{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: Embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNupFZ9fuSSHwYcWS7iFnYa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiBz5ORdbyn"
      },
      "source": [
        "# Embeddings \r\n",
        "# - these are capable of capturing the contextual, semantic and syntatic meaning in data.\r\n",
        "\r\n",
        "# While one-hot encoding allows us to preserve the structural info, it has two disadvantages \r\n",
        "# 1. linearly dependent on the number of unique token in the vocab which is problem if we have a large corpus\r\n",
        "# 2. the representation for each token does not preserve any relationship with respect to other tokens\r\n",
        "\r\n",
        "# Embeddings address the short comings of one-hot encoding\r\n",
        "# - its main idea is to have fixed length representations for the tokens in a text regardless of the tokens in the vocab\r\n",
        "# with one-hot encoding, each token is represented by an array of size vocab size but with embeddings, each token now has the shape embed dim\r\n",
        "###- the values in the rep are not fixed binary values but rather changing floating points allowing for fine-grained learned reps\r\n",
        "\r\n",
        "# the objective here is to rep tokens in text that capture the intrinsic semantic relationships\r\n",
        "## leveraging the low-dimensionality while capturing relationships and interpretable token reps."
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhvs0QObfR5u",
        "outputId": "faf7c97d-b164-4bb7-9310-7860daf62a20"
      },
      "source": [
        "# Learning Embeddings \r\n",
        "# - We can learn embeddings by creating our model in PyTorch, but first, we're going to use a library that specialises in embeddings and topic modelling called Gensim\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt');\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import urllib"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQot3XjrfxM_"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU7tcZAXf8Ff"
      },
      "source": [
        "# Set seed for reproducibility \r\n",
        "\r\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9KVbUSxgA91",
        "outputId": "4ad66d0f-e0df-4595-a7f3-89b994cdf2bc"
      },
      "source": [
        "# Split text into sentences \r\n",
        "\r\n",
        "tokeniser = nltk.data.load(\"tokenizers/punkt/english.pickle\")\r\n",
        "book = urllib.request.urlopen(url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/harrypotter.txt\")\r\n",
        "sentences = tokeniser.tokenize(str(book.read()))\r\n",
        "print (f\"{len(sentences)} sentences\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12443 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zpt221jgv4w"
      },
      "source": [
        "def preprocess(text):\r\n",
        "  \"\"\"Conditional preprocessing on our text.\"\"\"\r\n",
        "  # Lower\r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric characters \r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces\r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  # Separate into word tokens\r\n",
        "  text = text.split(\" \")\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHlGfLTmh5vH",
        "outputId": "1308c81f-a6d7-44b6-9d1e-d1b1bc79cb69"
      },
      "source": [
        "# Preprocess sentences\r\n",
        "print (sentences[11])\r\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\r\n",
        "print (sentences[11])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snape nodded, but did not elaborate.\n",
            "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvvySmmiPEz"
      },
      "source": [
        "# How doe we learn the embeddings in the first place?\r\n",
        "# The intuition behind embeddins is that the definition of a token depends NOT on the token itself, but on its context.\r\n",
        "# - There are several ways of doing this. \r\n",
        "# -- given the word in context, predict the target word (CBOW - continous bag of words)\r\n",
        "# -- given the target word, predict the context word (skip-gram)\r\n",
        "# -- given a sequence of words, predict the next word(LM - language modelling)\r\n",
        "\r\n",
        "# all these approaches involve the creation of data to train the model on. \r\n",
        "# Every word in a sentence becomes the target word and the context words are determined by a window\r\n",
        "# we repeat this for every sentence in the corpus and this results in the training data for unsupervised taskk\r\n",
        "\r\n",
        "# the idea is that similar target words will appear with similar contexts and we can learn this relationship by repeatedly training our model (wiht context and target) pairs"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "450GRspwiZcU"
      },
      "source": [
        "# Word2Vec\r\n",
        "\r\n",
        "# working with large vocabs to learn embeddings can become complicated quickly\r\n",
        "# Here, we can use the \"negative sampling\", which only updates the correct class and a few arbitrary incorrect classes \r\n",
        "# We can do this because of the large amoutn of training data where we will see the same word as the target class multiple times\r\n",
        "\r\n",
        "import gensim\r\n",
        "from gensim.models import KeyedVectors\r\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qup89Kc8lYFA"
      },
      "source": [
        "EMBEDDING_DIM = 100\r\n",
        "WINDOW = 5\r\n",
        "MIN_COUNT = 3 # ignores all the words with total frequency lower than this\r\n",
        "SKIP_GRAM = 1 # 0 = CBOW\r\n",
        "NEGATIVE_SAMPLING = 20"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcJuTmY3lqkf",
        "outputId": "b9d81a22-9c77-4864-c472-c85694de4870"
      },
      "source": [
        "# super fast because of optimised C code under the hood\r\n",
        "\r\n",
        "w2v = Word2Vec(sentences = sentences, size = EMBEDDING_DIM, window = WINDOW,\r\n",
        "               min_count = MIN_COUNT, sg = SKIP_GRAM, negative = NEGATIVE_SAMPLING)\r\n",
        "print (w2v)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKBOHpTxmEJc",
        "outputId": "67a9bb11-6759-426a-cdd1-9cdf78843f2d"
      },
      "source": [
        "# Vector for each word\r\n",
        "w2v.wv.get_vector(\"potter\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01697466, -0.2866405 , -0.3008265 , -0.29403865, -0.22781292,\n",
              "       -0.19741872, -0.0874659 ,  0.14124094,  0.58748853,  0.33553848,\n",
              "       -0.240756  , -0.04006175, -0.13412021,  0.17894153, -0.14883168,\n",
              "       -0.34405807,  0.27631482,  0.26866025, -0.5066555 ,  0.14108138,\n",
              "       -0.13761571, -0.3687644 , -0.06418797,  0.18793695, -0.2570797 ,\n",
              "        0.35075605,  0.13261083,  0.17419575, -0.05647279, -0.07211813,\n",
              "        0.59689295,  0.55984116, -0.01833745, -0.45927507, -0.34138373,\n",
              "       -0.0491113 ,  0.37332585, -0.3035386 , -0.4004415 , -0.06110671,\n",
              "       -0.00195717, -0.10445888, -0.28035152, -0.16219528,  0.2807279 ,\n",
              "        0.41262493,  0.0014628 , -0.35501745,  0.22529054, -0.25333297,\n",
              "        0.11366666,  0.25780088,  0.03564634,  0.04202371,  0.02636017,\n",
              "        0.04561004,  0.42189986,  0.01397108,  0.2692497 , -0.26579332,\n",
              "       -0.0788378 , -0.10421843, -0.23964319,  0.12406243,  0.17855582,\n",
              "        0.21702808, -0.31919608,  0.46681818, -0.22580583, -0.1442215 ,\n",
              "       -0.17711951, -0.31193984, -0.01348422, -0.1102741 ,  0.03378719,\n",
              "        0.18260476,  0.2524181 ,  0.16969748, -0.26153752, -0.05052852,\n",
              "        0.32046553, -0.17907579,  0.11205264, -0.50996053, -0.05544428,\n",
              "       -0.22829317, -0.11102615,  0.20979883, -0.08993088,  0.18029413,\n",
              "       -0.03732749, -0.24287714,  0.08354235, -0.20608968,  0.01449588,\n",
              "        0.15598959,  0.2703404 ,  0.11156769, -0.30567735, -0.08815683],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fXaF0SnmuzX",
        "outputId": "2ee5f487-6575-41ae-9cfe-d363e13363c7"
      },
      "source": [
        "# Get nearest neighbours (excluding itself)\r\n",
        "\r\n",
        "w2v.wv.most_similar(positive = \"scar\", topn = 5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forehead', 0.9274433255195618),\n",
              " ('pain', 0.9227378368377686),\n",
              " ('mouth', 0.9116102457046509),\n",
              " ('prickling', 0.9068350195884705),\n",
              " ('heart', 0.8966714143753052)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5RNaihm9sk"
      },
      "source": [
        "# Saving and loading \r\n",
        "\r\n",
        "w2v.wv.save_word2vec_format(\"model.bin\", binary = True)\r\n",
        "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary = True)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcmQyBXHnVxx"
      },
      "source": [
        "# FastText\r\n",
        "\r\n",
        "# What happens if a word doesnt exist in the vocab?\r\n",
        "# We could assign an \"UNK\" (unkown) token which is used for all OOV (out of vocab) words or we could use FastText, which uses character-level n-grams to embed a word\r\n",
        "# This helps embed rare words, misspelled words and also words that don't exist in our corpus but are similar to words in our corpus"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeI_6Qy-oE8W"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4GHCas5oJD0",
        "outputId": "67f63031-3d30-499f-cdcf-605ada3a0b19"
      },
      "source": [
        "# super fast because of the optimised C code under the hood\r\n",
        "\r\n",
        "ft = FastText(sentences = sentences, size = EMBEDDING_DIM, window = WINDOW, \r\n",
        "              min_count = MIN_COUNT, sg = SKIP_GRAM, negative = NEGATIVE_SAMPLING)\r\n",
        "print (ft)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt2OJ2IeojP_"
      },
      "source": [
        "# This word doesn't 'exist so the word2vec model will error out \r\n",
        "\r\n",
        "# w2v.wv.most_similar(positive = \"scarring\", topn = 5) # uncomment to check"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61VZl78o5Z6",
        "outputId": "6f41c9f2-79f2-464e-d867-b83c514479b3"
      },
      "source": [
        "# FastText on the other hand will use n-grams to embed an OOV word\r\n",
        "\r\n",
        "ft.wv.most_similar(positive = \"scarring\", topn = 10)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prickling', 0.9862031936645508),\n",
              " ('shuddering', 0.982107937335968),\n",
              " ('heartstring', 0.9814382791519165),\n",
              " ('brandishing', 0.9805978536605835),\n",
              " ('rippling', 0.9801949858665466),\n",
              " ('muffling', 0.980065107345581),\n",
              " ('shimmering', 0.9799435138702393),\n",
              " ('crumbling', 0.9794167280197144),\n",
              " ('shivering', 0.9788283109664917),\n",
              " ('compressing', 0.9781619310379028)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEC-9GUXpOug"
      },
      "source": [
        "# Save and load \r\n",
        "\r\n",
        "ft.wv.save(\"model.bin\")\r\n",
        "ft = KeyedVectors.load(\"model.bin\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxT2aaCEskm7"
      },
      "source": [
        "# Pretrained embeddings\r\n",
        "\r\n",
        "# - we can learn embeddings from scratch as above but we can also leverage pretrained embeddings that have been trained on millions of docs. \r\n",
        "# Popular ones include Word2Vec (skip gram) or GloVe(global word word co-occurence)\r\n",
        "# we can validate that these embeddings captured meaningful semantic relationships by confirming them \r\n",
        "\r\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\r\n",
        "from io import BytesIO\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from urllib.request import urlopen\r\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO10XHmueBe"
      },
      "source": [
        "# Arguments \r\n",
        "\r\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hj6gxJZvgwy"
      },
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\r\n",
        "  for word in words:\r\n",
        "    index = embeddings.index2word.index(word)\r\n",
        "    plt.scatter(pca_results[index, 0], pca_results[index, 1])\r\n",
        "    plt.annotate(word, xy = (pca_results[index, 0], pca_results[index, 1]))\r\n",
        "  plt.show()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0jZYCLNwRXe",
        "outputId": "4e082f44-e1bf-47a3-e4bd-5861807fa090"
      },
      "source": [
        "# Unzip the file (may a while)\r\n",
        "\r\n",
        "resp = urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\")\r\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\r\n",
        "zipfile.namelist()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B.50d.txt',\n",
              " 'glove.6B.100d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.6B.300d.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bP9SIfy_-i7A",
        "outputId": "b7046fb5-403c-4e57-d081-8395216a348b"
      },
      "source": [
        "# Write embeddings to file \r\n",
        "\r\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\r\n",
        "zipfile.extract(embeddings_file)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/glove.6B.100d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4zfsK7l-zz2",
        "outputId": "b9c0d75b-a885-497d-973e-4a77a4803c43"
      },
      "source": [
        "# Preview of the GloVe embeddings file \r\n",
        "\r\n",
        "with open(embeddings_file, \"r\") as fp:\r\n",
        "  line = next(fp)\r\n",
        "  values = line.split()\r\n",
        "  word = values[0]\r\n",
        "  embedding = np.asarray(values[1:], dtype = \"float32\")\r\n",
        "  print (f\"word: {word}\")\r\n",
        "  print (f\"embedding:\\n{embedding}\")\r\n",
        "  print (f\"embedding dim: {len(embedding)}\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57wk9nMK_ezh",
        "outputId": "a6f92b6a-3bca-4aaf-b2f4-c8de8418b105"
      },
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\r\n",
        "\r\n",
        "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\r\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF1aCx4J_4VW"
      },
      "source": [
        "# Load embeddings (may take a while)\r\n",
        "\r\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary = False)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbrBj9ZBAWvr",
        "outputId": "ad3e9bdc-b4a4-4a6a-ec12-1805b9c71784"
      },
      "source": [
        "# (king - man) + woman = ?\r\n",
        "\r\n",
        "glove.most_similar(positive = [\"woman\", \"king\"], negative = [\"man\"], topn = 5)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRSrgpJVBVpA",
        "outputId": "a83a5f25-643c-4c53-9999-8673fd476912"
      },
      "source": [
        "# Get nearest neighbours (excluding itself)\r\n",
        "\r\n",
        "glove.wv.most_similar(positive = \"goku\", topn = 5)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gohan', 0.7246542572975159),\n",
              " ('bulma', 0.6497020125389099),\n",
              " ('raistlin', 0.6443604230880737),\n",
              " ('skaar', 0.6316742897033691),\n",
              " ('guybrush', 0.6231324672698975)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wldVzSLBiLD",
        "outputId": "f8c31103-1665-445b-9d1d-a7f9091e979e"
      },
      "source": [
        "# Reduce dimensionality for plotting\r\n",
        "\r\n",
        "X = glove[glove.wv.vocab]\r\n",
        "pca = PCA(n_components = 2)\r\n",
        "pca_results = pca.fit_transform(X)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_ln19cDxByqT",
        "outputId": "6158c609-94ef-4bbb-d97e-d47e37722929"
      },
      "source": [
        "# Visualise \r\n",
        "\r\n",
        "plot_embeddings(words = [\"king\", \"queen\", \"man\", \"woman\"], \r\n",
        "                embeddings = glove, pca_results = pca_results)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wht5-zcCIcu",
        "outputId": "4140f693-de50-44c7-84f0-e32405605ec5"
      },
      "source": [
        "# Bias in embeddings \r\n",
        "\r\n",
        "glove.most_similar(positive = [\"woman\", \"doctor\"], negative = [\"man\"], topn = 5)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227346420288),\n",
              " ('physician', 0.7189429998397827),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750682592391968),\n",
              " ('dentist', 0.6726033687591553)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiecZFuGMJx"
      },
      "source": [
        "# Set up\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import random\r\n",
        "import torch\r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyRu4AHuHB18"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OsJFqfnyHDUT"
      },
      "source": [
        "def set_seeds(seed = 1234):\r\n",
        "  \"\"\"Set seeds for reproducibility.\"\"\"\r\n",
        "  np.random.seed(seed)\r\n",
        "  random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed_all(seed) # multi GPU"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-E4OTaqHZqe"
      },
      "source": [
        "# Set seeds for reproducibility \r\n",
        "\r\n",
        "set_seeds(seed = SEED)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AjAQLc8He2T",
        "outputId": "c1f77e0b-c21a-43c7-d3a5-35a33014c430"
      },
      "source": [
        "# Set device\r\n",
        "\r\n",
        "cuda = True\r\n",
        "device = torch.device(\"cuda\" if (\r\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\r\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\r\n",
        "if device.type == \"cuda\":\r\n",
        "  torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\r\n",
        "print (device)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "TPfA8iikH_sj",
        "outputId": "219a99f2-6870-4db9-94e8-3efea8d2d2e1"
      },
      "source": [
        "# Load data\r\n",
        "\r\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/news.csv\"\r\n",
        "df = pd.read_csv(url, header = 0) # load\r\n",
        "df = df.sample(frac = 1).reset_index(drop = True) #shuffle\r\n",
        "df.head()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNq1f59LIcAi"
      },
      "source": [
        "# Preprocessing \r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "import re"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_94oxHy5IqMy",
        "outputId": "7a8aa0bc-4acd-44db-e9ee-5635b79c7b94"
      },
      "source": [
        "nltk.download(\"stopwords\")\r\n",
        "STOPWORDS = stopwords.words(\"english\")\r\n",
        "print (STOPWORDS[:5])\r\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eBnEh6m1I7If"
      },
      "source": [
        "def preprocess(text, stopwords = STOPWORDS):\r\n",
        "  \"\"\"Conditional preprocessing on our text unique to our task.\"\"\"\r\n",
        "\r\n",
        "  # Lower\r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Remove stopwords\r\n",
        "  pattern = re.compile(r'\\b(' + r'|'.join(stopwords) + r')\\b\\s*')\r\n",
        "  text = pattern.sub('', text)\r\n",
        "\r\n",
        "  # Remove words in parenthesis\r\n",
        "  text = re.sub(r'\\([^)]*\\)', '', text)\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric chars\r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces\r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "7DFux85cLAff",
        "outputId": "5aab5ab1-c1df-4fde-d441-d1e7e61bb895"
      },
      "source": [
        "# Sample \r\n",
        "text = \"Greet week for the NYSE!\"\r\n",
        "preprocess(text = text)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'greet week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bm-AWjatLIvD",
        "outputId": "cae5df7b-9d4a-4144-d03b-29eb270b07e9"
      },
      "source": [
        "# Apply dataframe\r\n",
        "\r\n",
        "preprocessed_df = df.copy()\r\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\r\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfNx_gWdLgjA"
      },
      "source": [
        "# Split data \r\n",
        "\r\n",
        "import collections\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9waSC0uN3vB"
      },
      "source": [
        "TRAIN_SIZE = 0.7\r\n",
        "VAL_SIZE = 0.15\r\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHWaZpN2N9Hq"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\r\n",
        "    \"\"\"Split dataset into data splits.\"\"\"\r\n",
        "    X_train, X_, y_train, y_ = train_test_split(X, y, train_size=TRAIN_SIZE, stratify=y)\r\n",
        "    X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size=0.5, stratify=y_)\r\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-r89jqIN_mg"
      },
      "source": [
        "# Data\r\n",
        "X = preprocessed_df[\"title\"].values\r\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDeNkpFiOBg_",
        "outputId": "349d9d28-8469-4159-ce7b-0c0d2a07227d"
      },
      "source": [
        "# Create data splits\r\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\r\n",
        "    X=X, y=y, train_size=TRAIN_SIZE)\r\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\r\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\r\n",
        "print (f\"Sample point: {X_train[0]} → {y_train[0]}\")"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_test: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks → World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCmMVfDCOC7M"
      },
      "source": [
        "# Label encoding \r\n",
        "\r\n",
        "import itertools"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-a886mZrOJe_"
      },
      "source": [
        "class LabelEncoder(object):\r\n",
        "    \"\"\"Label encoder for tag labels.\"\"\"\r\n",
        "    def __init__(self, class_to_index={}):\r\n",
        "        self.class_to_index = class_to_index\r\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "        self.classes = list(self.class_to_index.keys())\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.class_to_index)\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return f\"<LabelEncoder(num_classes={len(self)})>\"\r\n",
        "\r\n",
        "    def fit(self, y):\r\n",
        "        classes = np.unique(y_train)\r\n",
        "        for i, class_ in enumerate(classes):\r\n",
        "            self.class_to_index[class_] = i\r\n",
        "        self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "        self.classes = list(self.class_to_index.keys())\r\n",
        "        return self\r\n",
        "\r\n",
        "    def encode(self, y):\r\n",
        "        encoded = np.zeros((len(y)), dtype=int)\r\n",
        "        for i, item in enumerate(y):\r\n",
        "            encoded[i] = self.class_to_index[item]\r\n",
        "        return encoded\r\n",
        "\r\n",
        "    def decode(self, y):\r\n",
        "        classes = []\r\n",
        "        for i, item in enumerate(y):\r\n",
        "            classes.append(self.index_to_class[item])\r\n",
        "        return classes\r\n",
        "\r\n",
        "    def save(self, fp):\r\n",
        "        with open(fp, 'w') as fp:\r\n",
        "            contents = {'class_to_index': self.class_to_index}\r\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load(cls, fp):\r\n",
        "        with open(fp, 'r') as fp:\r\n",
        "            kwargs = json.load(fp=fp)\r\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ynbuk4gfONyb",
        "outputId": "fdd7e7ce-214c-4269-e60b-76b9b7a3b6b1"
      },
      "source": [
        "# Encode\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "label_encoder.fit(y_train)\r\n",
        "NUM_CLASSES = len(label_encoder)\r\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzGcx_efOjvc",
        "outputId": "cb1be38d-ac0c-426c-99af-8780dbb395db"
      },
      "source": [
        "# Convert labels to tokens\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")\r\n",
        "y_train = label_encoder.encode(y_train)\r\n",
        "y_val = label_encoder.encode(y_val)\r\n",
        "y_test = label_encoder.encode(y_test)\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rD5Y02uLOmIO",
        "outputId": "e964f080-67a1-4017-c44b-92c8e29b2384"
      },
      "source": [
        "# Class weights\r\n",
        "counts = np.bincount(y_train)\r\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\r\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W1CTa49On-B"
      },
      "source": [
        "# Tokeniser \r\n",
        "\r\n",
        "import json\r\n",
        "from collections import Counter\r\n",
        "from more_itertools import take"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHiiZLBtO5lH"
      },
      "source": [
        "class Tokeniser(object):\r\n",
        "    def __init__(self, char_level, num_tokens=None,\r\n",
        "                 pad_token='<PAD>', oov_token='<UNK>',\r\n",
        "                 token_to_index=None):\r\n",
        "        self.char_level = char_level\r\n",
        "        self.separator = '' if self.char_level else ' '\r\n",
        "        if num_tokens: num_tokens -= 2 # pad + unk tokens\r\n",
        "        self.num_tokens = num_tokens\r\n",
        "        self.oov_token = oov_token\r\n",
        "        if not token_to_index:\r\n",
        "            token_to_index = {'<PAD>': 0, '<UNK>': 1}\r\n",
        "        self.token_to_index = token_to_index\r\n",
        "        self.index_to_token = {v: k for k, v in self.token_to_index.items()}\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.token_to_index)\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return f\"<Tokeniser(num_tokens={len(self)})>\"\r\n",
        "\r\n",
        "    def fit_on_texts(self, texts):\r\n",
        "        if self.char_level:\r\n",
        "            all_tokens = [token for text in texts for token in text]\r\n",
        "        if not self.char_level:\r\n",
        "            all_tokens = [token for text in texts for token in text.split(' ')]\r\n",
        "        counts = Counter(all_tokens).most_common(self.num_tokens)\r\n",
        "        self.min_token_freq = counts[-1][1]\r\n",
        "        for token, count in counts:\r\n",
        "            index = len(self)\r\n",
        "            self.token_to_index[token] = index\r\n",
        "            self.index_to_token[index] = token\r\n",
        "        return self\r\n",
        "\r\n",
        "    def texts_to_sequences(self, texts):\r\n",
        "        sequences = []\r\n",
        "        for text in texts:\r\n",
        "            if not self.char_level:\r\n",
        "                text = text.split(' ')\r\n",
        "            sequence = []\r\n",
        "            for token in text:\r\n",
        "                sequence.append(self.token_to_index.get(\r\n",
        "                    token, self.token_to_index[self.oov_token]))\r\n",
        "            sequences.append(np.asarray(sequence))\r\n",
        "        return sequences\r\n",
        "\r\n",
        "    def sequences_to_texts(self, sequences):\r\n",
        "        texts = []\r\n",
        "        for sequence in sequences:\r\n",
        "            text = []\r\n",
        "            for index in sequence:\r\n",
        "                text.append(self.index_to_token.get(index, self.oov_token))\r\n",
        "            texts.append(self.separator.join([token for token in text]))\r\n",
        "        return texts\r\n",
        "\r\n",
        "    def save(self, fp):\r\n",
        "        with open(fp, 'w') as fp:\r\n",
        "            contents = {\r\n",
        "                'char_level': self.char_level,\r\n",
        "                'oov_token': self.oov_token,\r\n",
        "                'token_to_index': self.token_to_index\r\n",
        "            }\r\n",
        "            json.dump(contents, fp, indent=4, sort_keys=False)\r\n",
        "\r\n",
        "    @classmethod\r\n",
        "    def load(cls, fp):\r\n",
        "        with open(fp, 'r') as fp:\r\n",
        "            kwargs = json.load(fp=fp)\r\n",
        "        return cls(**kwargs)"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZbY5bB4PDMG",
        "outputId": "c52c86e4-7790-4ae1-cb9f-c211550657e7"
      },
      "source": [
        "# Tokenise\r\n",
        "tokeniser = Tokeniser(char_level=False, num_tokens=5000)\r\n",
        "tokeniser.fit_on_texts(texts=X_train)\r\n",
        "VOCAB_SIZE = len(tokeniser)\r\n",
        "print (tokeniser)"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokeniser(num_tokens=5000)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKM2RVG1PIa2",
        "outputId": "013fbcbb-3748-4e36-c3cc-6fd6026ffb15"
      },
      "source": [
        "# Sample of tokens\r\n",
        "\r\n",
        "print (take(5, tokeniser.token_to_index.items()))\r\n",
        "print (f\"least freq token's freq: {tokeniser.min_token_freq}\") # use this to adjust num_tokens"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq token's freq: 14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2INCYW8PNLu",
        "outputId": "5bae01d7-b189-4237-8656-a45a1e81af21"
      },
      "source": [
        "# Convert texts to sequences of indices\r\n",
        "\r\n",
        "X_train = tokeniser.texts_to_sequences(X_train)\r\n",
        "X_val = tokeniser.texts_to_sequences(X_val)\r\n",
        "X_test = tokeniser.texts_to_sequences(X_test)\r\n",
        "preprocessed_text = tokeniser.sequences_to_texts([X_train[0]])[0]\r\n",
        "print (\"Text to indices:\\n\"\r\n",
        "    f\"  (preprocessed) → {preprocessed_text}\\n\"\r\n",
        "    f\"  (tokenized) → {X_train[0]}\")"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices:\n",
            "  (preprocessed) → china battles north korea nuclear talks\n",
            "  (tokenized) → [  16 1491  285  142  114   24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xblAcowHP5fm",
        "outputId": "3460125f-79f1-4daf-ca0e-52e7bdccc9bf"
      },
      "source": [
        "# Embedding layer \r\n",
        "\r\n",
        "# Inputs \r\n",
        "\r\n",
        "vocab_size = 10\r\n",
        "x = torch.randint(high = vocab_size, size = (1, 5))\r\n",
        "print (x)\r\n",
        "print (x.shape)"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[5, 1, 6, 5, 6]])\n",
            "torch.Size([1, 5])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oa6WLDUcQOeX",
        "outputId": "30c37c85-3754-4cd7-e8a1-2a95136b77d5"
      },
      "source": [
        "# Embedding layer \r\n",
        "\r\n",
        "embeddings = nn.Embedding(embedding_dim = 100, num_embeddings = vocab_size)\r\n",
        "print (embeddings.weight.shape)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CNg1Ri2QeQz",
        "outputId": "c2224f0f-c52a-4c3f-e818-ff8c50a9e0b4"
      },
      "source": [
        "# Embed the input\r\n",
        "\r\n",
        "embeddings(x).shape"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 100])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-I05CI96Qluy"
      },
      "source": [
        "# Padding \r\n",
        "\r\n",
        "def pad_sequences(sequences, max_seq_len=0):\r\n",
        "    \"\"\"Pad sequences to max length in sequence.\"\"\"\r\n",
        "    max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\r\n",
        "    padded_sequences = np.zeros((len(sequences), max_seq_len))\r\n",
        "    for i, sequence in enumerate(sequences):\r\n",
        "        padded_sequences[i][:len(sequence)] = sequence\r\n",
        "    return padded_sequences"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fL0ak1VrVAI0",
        "outputId": "7cef0380-990b-4e48-9abc-db9c45e81030"
      },
      "source": [
        "# 2D sequences\r\n",
        "padded = pad_sequences(X_train[0:3])\r\n",
        "print (padded.shape)\r\n",
        "print (padded)"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 6)\n",
            "[[1.600e+01 1.491e+03 2.850e+02 1.420e+02 1.140e+02 2.400e+01]\n",
            " [1.445e+03 2.300e+01 6.560e+02 2.197e+03 1.000e+00 0.000e+00]\n",
            " [1.200e+02 1.400e+01 1.955e+03 1.005e+03 1.529e+03 4.014e+03]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eefKzdSJVCBW"
      },
      "source": [
        "FILTER_SIZES = list(range(1, 4)) # uni, bi and tri grams"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6HYGCp1VGKB"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "    def __init__(self, X, y, max_filter_size):\r\n",
        "        self.X = X\r\n",
        "        self.y = y\r\n",
        "        self.max_filter_size = max_filter_size\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.y)\r\n",
        "\r\n",
        "    def __str__(self):\r\n",
        "        return f\"<Dataset(N={len(self)})>\"\r\n",
        "\r\n",
        "    def __getitem__(self, index):\r\n",
        "        X = self.X[index]\r\n",
        "        y = self.y[index]\r\n",
        "        return [X, y]\r\n",
        "\r\n",
        "    def collate_fn(self, batch):\r\n",
        "        \"\"\"Processing on a batch.\"\"\"\r\n",
        "        # Get inputs\r\n",
        "        X = np.array(batch, dtype=object)[:, 0]\r\n",
        "        y = np.stack(np.array(batch, dtype=object)[:, 1], axis=0)\r\n",
        "\r\n",
        "        # Pad sequences\r\n",
        "        X = pad_sequences(X)\r\n",
        "\r\n",
        "        # Cast\r\n",
        "        X = torch.LongTensor(X.astype(np.int32))\r\n",
        "        y = torch.LongTensor(y.astype(np.int32))\r\n",
        "\r\n",
        "        return X, y\r\n",
        "\r\n",
        "    def create_dataloader(self, batch_size, shuffle=False, drop_last=False):\r\n",
        "        return torch.utils.data.DataLoader(\r\n",
        "            dataset=self, batch_size=batch_size, collate_fn=self.collate_fn,\r\n",
        "            shuffle=shuffle, drop_last=drop_last, pin_memory=True)"
      ],
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZLm59-3VK3W",
        "outputId": "2d4e04bf-ea3e-4355-f64c-c9234c107161"
      },
      "source": [
        "# Create datasets\r\n",
        "max_filter_size = max(FILTER_SIZES)\r\n",
        "train_dataset = Dataset(X=X_train, y=y_train, max_filter_size=max_filter_size)\r\n",
        "val_dataset = Dataset(X=X_val, y=y_val, max_filter_size=max_filter_size)\r\n",
        "test_dataset = Dataset(X=X_test, y=y_test, max_filter_size=max_filter_size)\r\n",
        "print (\"Datasets:\\n\"\r\n",
        "    f\"  Train dataset:{train_dataset.__str__()}\\n\"\r\n",
        "    f\"  Val dataset: {val_dataset.__str__()}\\n\"\r\n",
        "    f\"  Test dataset: {test_dataset.__str__()}\\n\"\r\n",
        "    \"Sample point:\\n\"\r\n",
        "    f\"  X: {train_dataset[0][0]}\\n\"\r\n",
        "    f\"  y: {train_dataset[0][1]}\")"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets:\n",
            "  Train dataset:<Dataset(N=84000)>\n",
            "  Val dataset: <Dataset(N=18000)>\n",
            "  Test dataset: <Dataset(N=18000)>\n",
            "Sample point:\n",
            "  X: [  16 1491  285  142  114   24]\n",
            "  y: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L3qD2r72VNCH",
        "outputId": "d005dce6-027f-43a8-e560-f0245e4759d5"
      },
      "source": [
        "# Create dataloaders\r\n",
        "batch_size = 64\r\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size=batch_size)\r\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size=batch_size)\r\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size=batch_size)\r\n",
        "batch_X, batch_y = next(iter(train_dataloader))\r\n",
        "print (\"Sample batch:\\n\"\r\n",
        "    f\"  X: {list(batch_X.size())}\\n\"\r\n",
        "    f\"  y: {list(batch_y.size())}\\n\"\r\n",
        "    \"Sample point:\\n\"\r\n",
        "    f\"  X: {batch_X[0]}\\n\"\r\n",
        "    f\"  y: {batch_y[0]}\")"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            "  X: [64, 14]\n",
            "  y: [64]\n",
            "Sample point:\n",
            "  X: tensor([  16, 1491,  285,  142,  114,   24,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0])\n",
            "  y: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kfpy0uBwVTZs"
      },
      "source": [
        "# Model \r\n",
        "\r\n",
        "import math\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C51nIQamV66b"
      },
      "source": [
        "EMBEDDING_DIM = 100\r\n",
        "HIDDEN_DIM = 100\r\n",
        "DROPOUT_P = 0.1"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHIsS_65WDBs"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "  def __init__(self, embedding_dim, vocab_size, num_filters, \r\n",
        "               filter_sizes, hidden_dim, dropout_p, num_classes, \r\n",
        "               pretrained_embeddings = None, freeze_embeddings = False, \r\n",
        "               padding_idx = 0):\r\n",
        "    super(CNN, self).__init__()\r\n",
        "\r\n",
        "    # Filter sizes \r\n",
        "    self.filter_sizes = filter_sizes\r\n",
        "\r\n",
        "    # Initialise embeddings \r\n",
        "    if pretrained_embeddings is None:\r\n",
        "      self.embeddings = nn.Embedding(embedding_dim = embedding_dim, \r\n",
        "                                     num_embeddings = vocab_size, padding_idx = padding_idx)\r\n",
        "    else:\r\n",
        "      pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\r\n",
        "      self.embeddings = nn.Embedding(embedding_dim = embedding_dim,\r\n",
        "                                     num_embeddings = vocab_size, padding_idx = padding_idx, _weight = pretrained_embeddings)\r\n",
        "    \r\n",
        "    # Freeze embeddings or not\r\n",
        "    if freeze_embeddings:\r\n",
        "      self.embeddings.weight.requires_grad = False\r\n",
        "\r\n",
        "    # Conv weights\r\n",
        "    self.conv = nn.ModuleList([nn.Conv1d(in_channels = embedding_dim, \r\n",
        "                                         out_channels = num_filters, kernel_size = f) for f in filter_sizes])\r\n",
        "    \r\n",
        "    # Fully Connected weights \r\n",
        "    self.dropout = nn.Dropout(dropout_p)\r\n",
        "    self.fc1 = nn.Linear(num_filters * len(filter_sizes), hidden_dim)\r\n",
        "    self.fc2 = nn.Linear(hidden_dim, num_classes)\r\n",
        "  \r\n",
        "  def forward(self, inputs, channel_first = False, apply_softmax = False):\r\n",
        "\r\n",
        "    # Embed\r\n",
        "    x_in, = inputs\r\n",
        "    x_in = self.embeddings(x_in)\r\n",
        "\r\n",
        "    # Rearrange input so num_channels is in dim 1 (N, C, L)\r\n",
        "    if not channel_first:\r\n",
        "      x_in = x_in.transpose(1, 2)\r\n",
        "\r\n",
        "    # Conv outputs \r\n",
        "    z = []\r\n",
        "    max_seq_len = x_in.shape[2]\r\n",
        "    for i, f in enumerate(self.filter_sizes):\r\n",
        "      # SAME padding\r\n",
        "      padding_left = int((self.conv[i].stride[0] * (max_seq_len-1) - max_seq_len + self.filter_sizes[i]) / 2)\r\n",
        "      padding_right = int(math.ceil((self.conv[i].stride[0] * (max_seq_len -1) - max_seq_len + self.filter_sizes[i]) / 2))\r\n",
        "\r\n",
        "      # Conv + pool\r\n",
        "      _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\r\n",
        "      _z = F.max_pool1d(_z, _z.size(2)).squeeze(2)\r\n",
        "      z.append(_z)\r\n",
        "\r\n",
        "    # Concat conv outputs\r\n",
        "    z = torch.cat(z, 1)\r\n",
        "\r\n",
        "    # FC layers \r\n",
        "    z = self.fc1(z)\r\n",
        "    z = self.dropout(z)\r\n",
        "    y_pred = self.fc2(z)\r\n",
        "\r\n",
        "    if apply_softmax:\r\n",
        "      y_pred = F.softmax(y_pred, dim = 1)\r\n",
        "    return y_pred"
      ],
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oN-RzqAhWgi"
      },
      "source": [
        "# Using GloVe\r\n",
        "\r\n",
        "# here, we will create some utility functions to load the pretrained GloVe embeddings into the embedding layer \r\n",
        "\r\n",
        "def load_glove_embeddings(embeddings_file):\r\n",
        "  \"\"\"Load embeddings from a file.\"\"\"\r\n",
        "  embeddings = {}\r\n",
        "  with open(embeddings_file, \"r\") as fp:\r\n",
        "    for index, line in enumerate(fp):\r\n",
        "      values = line.split()\r\n",
        "      word = values[0]\r\n",
        "      embedding = np.asarray(values[1:], dtype = \"float32\")\r\n",
        "      embeddings[word] = embedding\r\n",
        "  return embeddings"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWif_05gkWly"
      },
      "source": [
        "def make_embeddings_matrix(embeddings, word_index, embedding_dim):\r\n",
        "  \"\"\"Create embeddings matrix to use in Embedding layer.\"\"\"\r\n",
        "  embedding_matrix = np.zeros((len(word_index), embedding_dim))\r\n",
        "  for word, i in word_index.items():\r\n",
        "    embedding_vector = embeddings.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "      embedding_matrix[i] = embedding_vector\r\n",
        "  return embedding_matrix"
      ],
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvqYgaU8lPQb",
        "outputId": "7f4cb666-cab1-4941-dcc3-bfef7ea1a129"
      },
      "source": [
        "# Create embeddings \r\n",
        "\r\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\r\n",
        "glove_embeddings = load_glove_embeddings(embeddings_file = embeddings_file)\r\n",
        "embedding_matrix = make_embeddings_matrix(embeddings = glove_embeddings, word_index = tokeniser.token_to_index, \r\n",
        "                                          embedding_dim = EMBEDDING_DIM)\r\n",
        "print (f\"<Embeddings(words = {embedding_matrix.shape[0]}, dim = {embedding_matrix.shape[1]})>\")"
      ],
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Embeddings(words = 5000, dim = 100)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JR35-Ka5mIHE"
      },
      "source": [
        "# Experiments\r\n",
        "\r\n",
        "import json\r\n",
        "from sklearn.metrics import precision_recall_fscore_support\r\n",
        "from torch.optim import Adam\r\n"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdm4NPgUma_-"
      },
      "source": [
        "NUM_FILTERS = 50\r\n",
        "LEARNING_RATE = 1e-3\r\n",
        "PATIENCE = 5\r\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "55qrRkx5mj79"
      },
      "source": [
        "class Trainer(object):\r\n",
        "    def __init__(self, model, device, loss = None, optimiser = None, scheduler = None):\r\n",
        "\r\n",
        "        # Set params\r\n",
        "        self.model = model\r\n",
        "        self.device = device\r\n",
        "        self.loss = loss\r\n",
        "        self.optimiser = optimiser\r\n",
        "        self.scheduler = scheduler\r\n",
        "\r\n",
        "    def train_step(self, dataloader):\r\n",
        "        \"\"\"Train step.\"\"\"\r\n",
        "        # Set model to train mode\r\n",
        "        self.model.train()\r\n",
        "        loss = 0.0\r\n",
        "\r\n",
        "        # Iterate over train batches\r\n",
        "        for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "            # Step\r\n",
        "            batch = [item.to(self.device) for item in batch]  # Set device\r\n",
        "            inputs, targets = batch[:-1], batch[-1]\r\n",
        "            self.optimiser.zero_grad()  # Reset gradients\r\n",
        "            z = self.model(inputs)  # Forward pass\r\n",
        "            J = self.loss(z, targets)  # Define loss\r\n",
        "            J.backward()  # Backward pass\r\n",
        "            self.optimiser.step()  # Update weights\r\n",
        "\r\n",
        "            # Cumulative Metrics\r\n",
        "            loss += (J.detach().item() - loss) / (i + 1)\r\n",
        "\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def eval_step(self, dataloader):\r\n",
        "        \"\"\"Validation or test step.\"\"\"\r\n",
        "        # Set model to eval mode\r\n",
        "        self.model.eval()\r\n",
        "        loss = 0.0\r\n",
        "        y_trues, y_probs = [], []\r\n",
        "\r\n",
        "        # Iterate over val batches\r\n",
        "        with torch.no_grad():\r\n",
        "            for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "                # Step\r\n",
        "                batch = [item.to(self.device) for item in batch]  # Set device\r\n",
        "                inputs, y_true = batch[:-1], batch[-1]\r\n",
        "                z = self.model(inputs)  # Forward pass\r\n",
        "                J = self.loss(z, y_true).item()\r\n",
        "\r\n",
        "                # Cumulative Metrics\r\n",
        "                loss += (J - loss) / (i + 1)\r\n",
        "\r\n",
        "                # Store outputs\r\n",
        "                y_prob = torch.sigmoid(z).cpu().numpy()\r\n",
        "                y_probs.extend(y_prob)\r\n",
        "                y_trues.extend(y_true.cpu().numpy())\r\n",
        "\r\n",
        "        return loss, np.vstack(y_trues), np.vstack(y_probs)\r\n",
        "\r\n",
        "    def predict_step(self, dataloader):\r\n",
        "        \"\"\"Prediction step.\"\"\"\r\n",
        "        # Set model to eval mode\r\n",
        "        self.model.eval()\r\n",
        "        y_probs = []\r\n",
        "\r\n",
        "        # Iterate over val batches\r\n",
        "        with torch.no_grad():\r\n",
        "            for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "                # Forward pass w/ inputs\r\n",
        "                inputs, targets = batch[:-1], batch[-1]\r\n",
        "                y_prob = self.model(inputs, apply_softmax=True)\r\n",
        "\r\n",
        "                # Store outputs\r\n",
        "                y_probs.extend(y_prob)\r\n",
        "\r\n",
        "        return np.vstack(y_probs)\r\n",
        "\r\n",
        "    def train(self, num_epochs, patience, train_dataloader, val_dataloader):\r\n",
        "        best_val_loss = np.inf\r\n",
        "        for epoch in range(num_epochs):\r\n",
        "            # Steps\r\n",
        "            train_loss = self.train_step(dataloader=train_dataloader)\r\n",
        "            val_loss, _, _ = self.eval_step(dataloader=val_dataloader)\r\n",
        "            self.scheduler.step(val_loss)\r\n",
        "\r\n",
        "            # Early stopping\r\n",
        "            if val_loss < best_val_loss:\r\n",
        "                best_val_loss = val_loss\r\n",
        "                best_model = self.model\r\n",
        "                _patience = patience  # reset _patience\r\n",
        "            else:\r\n",
        "                _patience -= 1\r\n",
        "            if not _patience:  # 0\r\n",
        "                print(\"Stopping early!\")\r\n",
        "                break\r\n",
        "\r\n",
        "            # Logging\r\n",
        "            print(\r\n",
        "                f\"Epoch: {epoch+1} | \"\r\n",
        "                f\"train_loss: {train_loss:.5f}, \"\r\n",
        "                f\"val_loss: {val_loss:.5f}, \"\r\n",
        "                f\"lr: {self.optimiser.param_groups[0]['lr']:.2E}, \"\r\n",
        "                f\"_patience: {_patience}\"\r\n",
        "            )\r\n",
        "        return best_model"
      ],
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLOgh-usnKO4"
      },
      "source": [
        "def get_performance(y_true, y_pred, classes):\r\n",
        "    \"\"\"Per-class performance metrics.\"\"\"\r\n",
        "    # Get metrics\r\n",
        "    performance = {'overall': {}, 'class': {}}\r\n",
        "    metrics = precision_recall_fscore_support(y_true, y_pred)\r\n",
        "\r\n",
        "    # Overall performance\r\n",
        "    performance['overall']['precision'] = np.mean(metrics[0])\r\n",
        "    performance['overall']['recall'] = np.mean(metrics[1])\r\n",
        "    performance['overall']['f1'] = np.mean(metrics[2])\r\n",
        "    performance['overall']['num_samples'] = np.float64(np.sum(metrics[3]))\r\n",
        "\r\n",
        "    # Per-class performance\r\n",
        "    for i in range(len(classes)):\r\n",
        "        performance['class'][classes[i]] = {\r\n",
        "            \"precision\": metrics[0][i],\r\n",
        "            \"recall\": metrics[1][i],\r\n",
        "            \"f1\": metrics[2][i],\r\n",
        "            \"num_samples\": np.float64(metrics[3][i])\r\n",
        "        }\r\n",
        "\r\n",
        "    return performance"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLRp2ms8nMnN"
      },
      "source": [
        "PRETRAINED_EMBEDDINGS = None\r\n",
        "FREEZE_EMBEDDINGS = False"
      ],
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvMRjjxYnUW8",
        "outputId": "4aa31ba1-ddf5-40bf-9d6e-3a69b086fb12"
      },
      "source": [
        "# Initialise model \r\n",
        "\r\n",
        "model = CNN(embedding_dim = EMBEDDING_DIM, vocab_size = VOCAB_SIZE, \r\n",
        "            num_filters = NUM_FILTERS, filter_sizes = FILTER_SIZES, \r\n",
        "            hidden_dim = HIDDEN_DIM, dropout_p = DROPOUT_P, num_classes = NUM_CLASSES, \r\n",
        "            pretrained_embeddings = PRETRAINED_EMBEDDINGS, freeze_embeddings = FREEZE_EMBEDDINGS)\r\n",
        "model = model.to(device) # set device\r\n",
        "\r\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVW5olOlpIbB"
      },
      "source": [
        "# Define Loss\r\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\r\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slxnCSMbpa15"
      },
      "source": [
        "# Define optimizer & scheduler\r\n",
        "optimiser = Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimiser, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erp9371Hpcjd"
      },
      "source": [
        "# Trainer module\r\n",
        "trainer = Trainer(\r\n",
        "    model=model, device=device, loss=loss,\r\n",
        "    optimiser=optimiser, scheduler=scheduler)"
      ],
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkchvxVXpe2Q",
        "outputId": "67b56a8c-9841-4606-89d0-56cab70f1a2e"
      },
      "source": [
        "# Train\r\n",
        "best_model = trainer.train(\r\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.76718, val_loss: 0.58872, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.49107, val_loss: 0.55072, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.40240, val_loss: 0.56294, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.34255, val_loss: 0.60096, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.29370, val_loss: 0.66315, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.25373, val_loss: 0.72333, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOz1W1jFqQA6"
      },
      "source": [
        "# Get predictions\r\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgQAJNGnqT--",
        "outputId": "414574f6-48f2-4854-8dd8-dd1e7c203d22"
      },
      "source": [
        "# Determine performance\r\n",
        "performance = get_performance(\r\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\r\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 181,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8101679112036401,\n",
            "  \"recall\": 0.8088333333333333,\n",
            "  \"f1\": 0.809253011881923,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS266OnwqWgV"
      },
      "source": [
        "# GloVe (frozen)\r\n",
        "PRETRAINED_EMBEDDINGS = embedding_matrix\r\n",
        "FREEZE_EMBEDDINGS = True\r\n"
      ],
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPzSl98Kqdqf",
        "outputId": "93f92aa7-afff-4f99-d0ab-e46fd46c50aa"
      },
      "source": [
        "# Initialize model\r\n",
        "model = CNN(\r\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\r\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\r\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\r\n",
        "model = model.to(device) # set device\r\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icq8x2JyrMwg"
      },
      "source": [
        "# Define Loss\r\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\r\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rym8psZWrO3g"
      },
      "source": [
        "# Define optimizer & scheduler\r\n",
        "optimiser = Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimiser, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8JIc7QWrTpX"
      },
      "source": [
        "# Trainer module\r\n",
        "trainer = Trainer(\r\n",
        "    model=model, device=device, loss=loss,\r\n",
        "    optimiser=optimiser, scheduler=scheduler)"
      ],
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpk-BybUrWs1",
        "outputId": "221e95ff-6bb3-49a6-8868-3235f5ad55f9"
      },
      "source": [
        "# Train\r\n",
        "best_model = trainer.train(\r\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": 189,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.51623, val_loss: 0.47505, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.44337, val_loss: 0.46294, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.41203, val_loss: 0.46383, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.38774, val_loss: 0.46976, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.36891, val_loss: 0.48075, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.35252, val_loss: 0.49133, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n2jax4s2ra_E"
      },
      "source": [
        "# Get predictions\r\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HN5_piCrhOJ",
        "outputId": "913ca125-5df6-4c8c-8fec-087d135f756d"
      },
      "source": [
        "# Determine performance\r\n",
        "performance = get_performance(\r\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\r\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8329081942245948,\n",
            "  \"recall\": 0.8323888888888888,\n",
            "  \"f1\": 0.832367757305705,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gP7_cAuprrg8"
      },
      "source": [
        "# GloVE (fine tuned)\r\n",
        "PRETRAINED_EMBEDDINGS = embedding_matrix\r\n",
        "FREEZE_EMBEDDINGS = False"
      ],
      "execution_count": 192,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzlmxO8hrx8f",
        "outputId": "c7768dbd-5275-4878-9329-0330ca69e235"
      },
      "source": [
        "# Initialize model\r\n",
        "model = CNN(\r\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\r\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\r\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\r\n",
        "model = model.to(device) # set device\r\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 193,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
            "  (conv): ModuleList(\n",
            "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
            "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
            "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
            "  )\n",
            "  (dropout): Dropout(p=0.1, inplace=False)\n",
            "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrEveT7NrzmZ"
      },
      "source": [
        "# Define Loss\r\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\r\n",
        "loss = nn.CrossEntropyLoss(weight=class_weights_tensor)"
      ],
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8nKQURBAr8Et"
      },
      "source": [
        "# Define optimiser & scheduler\r\n",
        "optimiser = Adam(model.parameters(), lr=LEARNING_RATE)\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimiser, mode='min', factor=0.1, patience=3)"
      ],
      "execution_count": 196,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41rVNF82sAXQ"
      },
      "source": [
        "# Trainer module\r\n",
        "trainer = Trainer(\r\n",
        "    model=model, device=device, loss=loss,\r\n",
        "    optimiser=optimiser, scheduler=scheduler)"
      ],
      "execution_count": 198,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDQNtqBxsGDP",
        "outputId": "96a58260-34a7-434b-b603-56388cb214f4"
      },
      "source": [
        "# Train\r\n",
        "best_model = trainer.train(\r\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": 199,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.48926, val_loss: 0.44469, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.39026, val_loss: 0.44103, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.34401, val_loss: 0.45837, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 4 | train_loss: 0.29974, val_loss: 0.49504, lr: 1.00E-03, _patience: 3\n",
            "Epoch: 5 | train_loss: 0.25475, val_loss: 0.55088, lr: 1.00E-03, _patience: 2\n",
            "Epoch: 6 | train_loss: 0.21122, val_loss: 0.63680, lr: 1.00E-04, _patience: 1\n",
            "Stopping early!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRa1DwLmsLSI"
      },
      "source": [
        "# Get predictions\r\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader=test_dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis=1)"
      ],
      "execution_count": 200,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-KsQ6cPsRi0",
        "outputId": "9d6b0494-a568-45f6-b284-3d37910fcfd2"
      },
      "source": [
        "# Determine performance\r\n",
        "performance = get_performance(\r\n",
        "    y_true=y_test, y_pred=y_pred, classes=label_encoder.classes)\r\n",
        "print (json.dumps(performance['overall'], indent=2))"
      ],
      "execution_count": 201,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.8305410534205683,\n",
            "  \"recall\": 0.8301666666666666,\n",
            "  \"f1\": 0.8302706249646987,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K71DedKYsS61"
      },
      "source": [
        "# Save artifacts\r\n",
        "from pathlib import Path\r\n",
        "dir = Path(\"cnn\")\r\n",
        "dir.mkdir(parents=True, exist_ok=True)\r\n",
        "label_encoder.save(fp=Path(dir, 'label_encoder.json'))\r\n",
        "tokeniser.save(fp=Path(dir, 'tokeniser.json'))\r\n",
        "torch.save(best_model.state_dict(), Path(dir, 'model.pt'))\r\n",
        "with open(Path(dir, 'performance.json'), \"w\") as fp:\r\n",
        "    json.dump(performance, indent=2, sort_keys=False, fp=fp)"
      ],
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JIt-62osWDd"
      },
      "source": [
        "# inference \r\n",
        "\r\n",
        "def get_probability_distribution(y_prob, classes):\r\n",
        "    \"\"\"Create a dict of class probabilities from an array.\"\"\"\r\n",
        "    results = {}\r\n",
        "    for i, class_ in enumerate(classes):\r\n",
        "        results[class_] = np.float64(y_prob[i])\r\n",
        "    sorted_results = {k: v for k, v in sorted(\r\n",
        "        results.items(), key=lambda item: item[1], reverse=True)}\r\n",
        "    return sorted_results"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TumzV8QtxnG",
        "outputId": "704a32d6-9702-42b8-8490-839e80f7c057"
      },
      "source": [
        "# Load artifacts\r\n",
        "device = torch.device(\"cpu\")\r\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\r\n",
        "tokeniser = Tokeniser.load(fp=Path(dir, 'tokeniser.json'))\r\n",
        "model = CNN(\r\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\r\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\r\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\r\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\r\n",
        "model.to(device)"
      ],
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 206
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruIJL5oHtzII"
      },
      "source": [
        "# Initialize trainer\r\n",
        "trainer = Trainer(model=model, device=device)"
      ],
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AGHGk4FOt5GN",
        "outputId": "1a7ec235-b12a-476e-9e49-eb2329604fc4"
      },
      "source": [
        "# Dataloader\r\n",
        "text = \"The final tennis tournament starts next week.\"\r\n",
        "X = tokeniser.texts_to_sequences([preprocess(text)])\r\n",
        "print (tokeniser.sequences_to_texts(X))\r\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]]*len(X))\r\n",
        "dataset = Dataset(X=X, y=y_filler, max_filter_size=max_filter_size)\r\n",
        "dataloader = dataset.create_dataloader(batch_size=batch_size)"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['final tennis tournament starts next week']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uxYKL1Zgt6ba",
        "outputId": "e5e0502d-5d46-41e3-a1bb-df1672d201d2"
      },
      "source": [
        "# Inference\r\n",
        "y_prob = trainer.predict_step(dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis=1)\r\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Sports']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKeVpf0yuAwa",
        "outputId": "b0d6f26a-3789-4d68-bb2c-99d10c963ab1"
      },
      "source": [
        "# Class distributions\r\n",
        "prob_dist = get_probability_distribution(y_prob=y_prob[0], classes=label_encoder.classes)\r\n",
        "print (json.dumps(prob_dist, indent=2))"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Sports\": 0.9999998807907104,\n",
            "  \"World\": 1.7412990871434886e-07,\n",
            "  \"Sci/Tech\": 8.365978132474083e-09,\n",
            "  \"Business\": 6.17230710986405e-10\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oBiEOweuCsU"
      },
      "source": [
        "# Interpretability \r\n",
        "\r\n",
        "import collections\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 212,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cF3mKW9WuI-i"
      },
      "source": [
        "class InterpretableCNN(nn.Module):\r\n",
        "    def __init__(self, embedding_dim, vocab_size, num_filters,\r\n",
        "                 filter_sizes, hidden_dim, dropout_p, num_classes,\r\n",
        "                 pretrained_embeddings=None, freeze_embeddings=False,\r\n",
        "                 padding_idx=0):\r\n",
        "        super(InterpretableCNN, self).__init__()\r\n",
        "\r\n",
        "        # Filter sizes\r\n",
        "        self.filter_sizes = filter_sizes\r\n",
        "\r\n",
        "        # Initialize embeddings\r\n",
        "        if pretrained_embeddings is None:\r\n",
        "            self.embeddings = nn.Embedding(\r\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\r\n",
        "                padding_idx=padding_idx)\r\n",
        "        else:\r\n",
        "            pretrained_embeddings = torch.from_numpy(pretrained_embeddings).float()\r\n",
        "            self.embeddings = nn.Embedding(\r\n",
        "                embedding_dim=embedding_dim, num_embeddings=vocab_size,\r\n",
        "                padding_idx=padding_idx, _weight=pretrained_embeddings)\r\n",
        "\r\n",
        "        # Freeze embeddings or not\r\n",
        "        if freeze_embeddings:\r\n",
        "            self.embeddings.weight.requires_grad = False\r\n",
        "\r\n",
        "        # Conv weights\r\n",
        "        self.conv = nn.ModuleList(\r\n",
        "            [nn.Conv1d(in_channels=embedding_dim,\r\n",
        "                       out_channels=num_filters,\r\n",
        "                       kernel_size=f) for f in filter_sizes])\r\n",
        "\r\n",
        "        # FC weights\r\n",
        "        self.dropout = nn.Dropout(dropout_p)\r\n",
        "        self.fc1 = nn.Linear(num_filters*len(filter_sizes), hidden_dim)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\r\n",
        "\r\n",
        "    def forward(self, inputs, channel_first=False, apply_softmax=False):\r\n",
        "\r\n",
        "        # Embed\r\n",
        "        x_in, = inputs\r\n",
        "        x_in = self.embeddings(x_in)\r\n",
        "\r\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\r\n",
        "        if not channel_first:\r\n",
        "            x_in = x_in.transpose(1, 2)\r\n",
        "\r\n",
        "        # Conv outputs\r\n",
        "        z = []\r\n",
        "        max_seq_len = x_in.shape[2]\r\n",
        "        for i, f in enumerate(self.filter_sizes):\r\n",
        "            # `SAME` padding\r\n",
        "            padding_left = int((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2)\r\n",
        "            padding_right = int(math.ceil((self.conv[i].stride[0]*(max_seq_len-1) - max_seq_len + self.filter_sizes[i])/2))\r\n",
        "\r\n",
        "            # Conv + pool\r\n",
        "            _z = self.conv[i](F.pad(x_in, (padding_left, padding_right)))\r\n",
        "            z.append(_z.cpu().numpy())\r\n",
        "\r\n",
        "        return z"
      ],
      "execution_count": 213,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BalQlW_TuMdi"
      },
      "source": [
        "PRETRAINED_EMBEDDINGS = embedding_matrix\r\n",
        "FREEZE_EMBEDDINGS = False"
      ],
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb9o4TouuORY",
        "outputId": "d4a5b76f-8d8b-44eb-b1c3-498b99c64c0e"
      },
      "source": [
        "# Initialize model\r\n",
        "interpretable_model = InterpretableCNN(\r\n",
        "    embedding_dim=EMBEDDING_DIM, vocab_size=VOCAB_SIZE,\r\n",
        "    num_filters=NUM_FILTERS, filter_sizes=FILTER_SIZES,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES,\r\n",
        "    pretrained_embeddings=PRETRAINED_EMBEDDINGS, freeze_embeddings=FREEZE_EMBEDDINGS)\r\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\r\n",
        "interpretable_model.to(device)"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (embeddings): Embedding(5000, 100, padding_idx=0)\n",
              "  (conv): ModuleList(\n",
              "    (0): Conv1d(100, 50, kernel_size=(1,), stride=(1,))\n",
              "    (1): Conv1d(100, 50, kernel_size=(2,), stride=(1,))\n",
              "    (2): Conv1d(100, 50, kernel_size=(3,), stride=(1,))\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc1): Linear(in_features=150, out_features=100, bias=True)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 215
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLVYtyqGuPxw"
      },
      "source": [
        "# Initialize trainer\r\n",
        "interpretable_trainer = Trainer(model=interpretable_model, device=device)"
      ],
      "execution_count": 216,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHZOgkUluRp6",
        "outputId": "3fe5a911-761b-4b2d-ded5-54cd87d58812"
      },
      "source": [
        "# Get conv outputs\r\n",
        "conv_outputs = interpretable_trainer.predict_step(dataloader)\r\n",
        "print (conv_outputs.shape) # (len(filter_sizes), num_filters, max_seq_len)"
      ],
      "execution_count": 217,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 50, 6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "7j1C9w8FuUD8",
        "outputId": "2408d9f3-04b6-4d35-a0af-eb34cba03567"
      },
      "source": [
        "# Visualize a bi-gram filter's outputs\r\n",
        "tokens = tokeniser.sequences_to_texts(X)[0].split(' ')\r\n",
        "sns.heatmap(conv_outputs[1], xticklabels=tokens)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f7aa0c9c438>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQz05BLkuWOp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}