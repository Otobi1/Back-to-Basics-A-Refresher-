{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: CNNs",
      "provenance": [],
      "authorship_tag": "ABX9TyPL1JxaPxOFKugk9Rmh/9K0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSEYD28OfPkb"
      },
      "source": [
        "## Set up \r\n",
        "\r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import random \r\n",
        "import torch \r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759r6mk1ZUM_"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MqZJHqAZV1x"
      },
      "source": [
        "def set_seeds(seed = 1234):\r\n",
        "  \"\"\"Set seed for reproducibility.\"\"\"\r\n",
        "  np.random.seed(seed)\r\n",
        "  random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed_all(seed) # multi GPU"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP0JoHAEZ2XM"
      },
      "source": [
        "# Set seed for reproducibility \r\n",
        "\r\n",
        "set_seeds(seed=SEED)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWPpxlKIawys",
        "outputId": "c4319735-5d68-442f-db54-87c4164894ad"
      },
      "source": [
        "# Set device \r\n",
        "\r\n",
        "cuda = True\r\n",
        "device = torch.device(\"cuda\" if (\r\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\r\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\r\n",
        "if device.type == \"cuda\":\r\n",
        "  torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\r\n",
        "print (device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "hNTtW2TjbX90",
        "outputId": "8e0ec4f2-d419-491e-ff01-3668fde69d31"
      },
      "source": [
        "# Load data \r\n",
        "# - corpus of news article from http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html \r\n",
        "\r\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/news.csv\"\r\n",
        "df = pd.read_csv(url, header = 0) # load\r\n",
        "df = df.sample(frac = 1).reset_index(drop = True) # shuffle\r\n",
        "df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NlO6lmtb5rN"
      },
      "source": [
        "# Preprocessing \r\n",
        "# - to clean up the data, convert to lower text, remove filler words and filter using regex.\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "import re"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDTD_WxOcgyF",
        "outputId": "37f7b872-9f94-46e9-aaed-bae900d7f7ba"
      },
      "source": [
        "nltk.download(\"stopwords\")\r\n",
        "STOPWORDS = stopwords.words(\"english\")\r\n",
        "print (STOPWORDS[:5])\r\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0oH6OeZdQld"
      },
      "source": [
        "def preprocess(text, stopwords = STOPWORDS):\r\n",
        "  \"\"\"Conditional preprocessing on our text unique to the task.\"\"\"\r\n",
        "  # Lower \r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Remove stopwords\r\n",
        "  pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\r\n",
        "  text = pattern.sub(\" \", text)\r\n",
        "\r\n",
        "  # Remove words in parenthesis\r\n",
        "  text = re.sub(r\"\\([^)]*\\)\", \" \", text)\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric characters\r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces \r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K-DBYnbtgJXf",
        "outputId": "b10f88f2-27f1-4bb1-c5e9-eb9ae0fab17f"
      },
      "source": [
        "# Sample \r\n",
        "\r\n",
        "text = \"Great week for the NYSE\"\r\n",
        "preprocess(text = text)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVH3XrNgmJk",
        "outputId": "7712e86f-d766-4051-dd47-e3c2ba074630"
      },
      "source": [
        "# Apply to dataframe\r\n",
        "\r\n",
        "preprocessed_df = df.copy()\r\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\r\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TLGqCnLhMJL"
      },
      "source": [
        "# if you have preprocessing steps like standardisation, that are calculated, you need to separate the training an dtest set first before applying those operations. \r\n",
        "# this is because we cannot apply any knowledge gained from the test set accidentally (data leak during preprocessing/training). \r\n",
        "# - for global preprocessing steps like the functin above, where we arent learning anything from the data itself, we can perform them before splitting the data."
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvGalMXshdP5"
      },
      "source": [
        "# Split the data \r\n",
        "\r\n",
        "import collections\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2_5ayPKh7ak"
      },
      "source": [
        "TRAIN_SIZE = 0.7\r\n",
        "VAL_SIZE = 0.15\r\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToTVRdVRiu6m"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\r\n",
        "  \"\"\"Split dataset into data split.\"\"\"\r\n",
        "  X_train, X_, y_train, y_ = train_test_split(X, y, train_size = TRAIN_SIZE, stratify = y)\r\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size = 0.5, stratify = y_)\r\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dHEIRQjZoX"
      },
      "source": [
        "# Data\r\n",
        "X = preprocessed_df[\"title\"].values \r\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJxEUiLbjh4V",
        "outputId": "10f0fd65-060a-44f4-ba06-0fe5499d75b9"
      },
      "source": [
        "# Create data splits\r\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\r\n",
        "    X = X, y = y, train_size = TRAIN_SIZE)\r\n",
        "\r\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\r\n",
        "print (f\"X_train: {X_test.shape}, y_test: {y_test.shape}\")\r\n",
        "print (f\"Sample point: {X_train[0]} -> {y_train[0]}\")\r\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_train: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks -> World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtvU0BHUkSEr"
      },
      "source": [
        "# Label Encoding \r\n",
        "# to encode the text labels into unique indices\r\n",
        "\r\n",
        "import itertools"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2cewudKkgVY"
      },
      "source": [
        "class LabelEncoder(object):\r\n",
        "  \"\"\"Label encoder for tag labels.\"\"\"\r\n",
        "  def __init__(self, class_to_index = {}):\r\n",
        "    self.class_to_index = class_to_index\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.class_to_index)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<LabelEncoder(num_classes = {len(self)})>\"\r\n",
        "  \r\n",
        "  def fit(self, y):\r\n",
        "    classes = np.unique(y_train)\r\n",
        "    for i, class_ in enumerate(classes):\r\n",
        "      self.class_to_index[class_] = i\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "    return self\r\n",
        "\r\n",
        "  def encode(self, y):\r\n",
        "    encoded = np.zeros((len(y)), dtype = int)\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      encoded[i] = self.class_to_index[item]\r\n",
        "    return encoded\r\n",
        "\r\n",
        "  def decode(self, y):\r\n",
        "    classes = []\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      classes.append(self.index_to_class[item])\r\n",
        "    return classes\r\n",
        "\r\n",
        "  def save(self, fp):\r\n",
        "    with open(fp, \"w\") as fp:\r\n",
        "      contents = {\"class_to_index\": self.class_to_index}\r\n",
        "      json.dump(contents, fp, indent = 4, sort_keys = False)\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def load(cls, fp):\r\n",
        "    with open(fp, \"r\") as fp:\r\n",
        "      kwargs = json.load(fp = fp)\r\n",
        "    return clas(**kwargs)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwntyBauo_QA",
        "outputId": "6c3d0307-40ed-4b19-e4a2-da8d13e303b5"
      },
      "source": [
        "# Encode \r\n",
        "\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "label_encoder.fit(y_train)\r\n",
        "NUM_CLASSES = len(label_encoder)\r\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHY1TClrpXP6",
        "outputId": "d044b440-13b3-4e3a-f2ca-d502711cd6fa"
      },
      "source": [
        "# Converting labels to tokens \r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")\r\n",
        "\r\n",
        "y_train = label_encoder.encode(y_train)\r\n",
        "y_val = label_encoder.encode(y_val)\r\n",
        "y_test = label_encoder.encode(y_test)\r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFHTuNzTp3sq",
        "outputId": "45792ff5-68b2-459c-a35a-f5be024f3a20"
      },
      "source": [
        "# Class weights \r\n",
        "\r\n",
        "counts = np.bincount(y_train)\r\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\r\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDrlCrFrD_3"
      },
      "source": [
        "# Tokenizer \r\n",
        "\r\n",
        "import json\r\n",
        "from collections import Counter\r\n",
        "from more_itertools import take"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFX9mkPwriDZ"
      },
      "source": [
        "class Tokeniser(object):\r\n",
        "  def __init__(self, char_level, num_tokens = None,\r\n",
        "               pad_token = \"<PAD>\", oov_token = \"<UNK>\", \r\n",
        "               token_to_index = None):\r\n",
        "    self.char_level = char_level\r\n",
        "    self.separator = \" \" if self.char_level else \" \"\r\n",
        "    if num_tokens: num_tokens -= 2 # pad + unk tokens\r\n",
        "    self.num_tokens = num_tokens\r\n",
        "    self.oov_token = oov_token\r\n",
        "    if not token_to_index:\r\n",
        "      token_to_index = {\"<PAD>\": 0, \"<UNK>\": 1}\r\n",
        "    self.token_to_index = token_to_index\r\n",
        "    self.index_to_token = {v: k for k, v in self.token_to_index.items()}\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.token_to_index)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<Tokeniser(num_tokens = {len(self)})>\"\r\n",
        "\r\n",
        "  def fit_on_texts(self, texts):\r\n",
        "    if self.char_level:\r\n",
        "      all_tokens = [token for text in texts for token in text]\r\n",
        "    if not self.char_level:\r\n",
        "      all_tokens = [token for text in texts for token in text.split(\" \")]\r\n",
        "    counts = Counter(all_tokens).most_common(self.num_tokens)\r\n",
        "    self.min_token_freq = counts[-1][1]\r\n",
        "    for token, count in counts:\r\n",
        "      index = len(self)\r\n",
        "      self.token_to_index[token] = index\r\n",
        "      self.index_to_token[index] = token\r\n",
        "    return self\r\n",
        "\r\n",
        "  def texts_to_sequence(self, texts):\r\n",
        "    sequences = []\r\n",
        "    for text in texts:\r\n",
        "      if not self.char_level:\r\n",
        "        text = text.split(' ')\r\n",
        "      sequence = []\r\n",
        "      for token in text: \r\n",
        "        sequence.append(self.token_to_index.get(\r\n",
        "            token, self.token_to_index[self.oov_token]))\r\n",
        "      sequences.append(np.asarray(sequence))\r\n",
        "    return sequences\r\n",
        "  \r\n",
        "  def sequences_to_texts(self, sequences):\r\n",
        "    texts = []\r\n",
        "    for sequence in sequences:\r\n",
        "      text = []\r\n",
        "      for index in sequence :\r\n",
        "        text.append(self.index_to_token.get(index, self.oov_token))\r\n",
        "      texts.append(self.separator.join([token for token in text]))\r\n",
        "    return texts\r\n",
        "  \r\n",
        "  def save(self, fp):\r\n",
        "    with open(fp, \"w\") as fp:\r\n",
        "      contents = {\r\n",
        "          \"char_level\": self.char_level, \r\n",
        "          \"oov_token\": self.oov_token, \r\n",
        "          \"token_to_index\": self.token_to_index\r\n",
        "      }\r\n",
        "      json.dump(contents, fp, indent = 4, sort_keys = False)\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def load(cls, fp):\r\n",
        "    with open(fp, \"r\") as fp:\r\n",
        "      kwargs = json.load(fp = fp)\r\n",
        "    return cls(**kwargs)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTZBh3bAwQUL"
      },
      "source": [
        "## - we will restrict the number of tokens in our tokenizer to the top 500 most frequent tokens (stop words already removed)\r\n",
        "# -- because the full vocabulary (approx 30k) is too large to run on google colab\r\n",
        "\r\n",
        "# ** it is important that we are only using the training data split because during inference, the model will not always know every token\r\n",
        "# -- so it is important to replicate that scenario with the validation and test split. "
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSQgaU3sxiWJ",
        "outputId": "b970ad7b-fd64-4c04-e5e0-b320440540f9"
      },
      "source": [
        "# Tokenise\r\n",
        "\r\n",
        "tokeniser = Tokeniser(char_level = False, num_tokens = 500)\r\n",
        "tokeniser.fit_on_texts(texts = X_train)\r\n",
        "VOCAB_SIZE = len(tokeniser)\r\n",
        "\r\n",
        "print (tokeniser)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokeniser(num_tokens = 500)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCShuyiwyXQc",
        "outputId": "c0040ac5-a408-4fe3-8bc7-67c7a6352dea"
      },
      "source": [
        "# Sample of tokens \r\n",
        "\r\n",
        "print (take(5, tokeniser.token_to_index.items()))\r\n",
        "print (f\"least freq tokens freq: {tokeniser.min_token_freq}\") # use this to adjust num tokens"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq tokens freq: 166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y1tmtwozS5O",
        "outputId": "31ef4c01-1e79-47d3-d2d4-88b2acfe366d"
      },
      "source": [
        "# Convert texts to sequences of indices \r\n",
        "\r\n",
        "X_train = tokeniser.texts_to_sequence(X_train)\r\n",
        "X_val = tokeniser.texts_to_sequence(X_val)\r\n",
        "X_test = tokeniser.texts_to_sequence(X_test)\r\n",
        "\r\n",
        "preprocessed_text = tokeniser.sequences_to_texts([X_train[0]])[0]\r\n",
        "print (\"Text to indices: \\n\"\r\n",
        "    f\" (preprocessed) -> {preprocessed_text}\\n\"\r\n",
        "    f\" (tokenised) -> {X_train[0]}\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices: \n",
            " (preprocessed) -> china <UNK> north korea nuclear talks\n",
            " (tokenised) -> [ 16   1 285 142 114  24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXswfqRo0GmE"
      },
      "source": [
        "# One-hot Encoding \r\n",
        "\r\n",
        "# - Creates a binary column fro each unique value of each feature. \r\n",
        "# -- All the values for the token will be 0 except the index of that specific token"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG7EDYm513fS"
      },
      "source": [
        "def to_categorical(seq, num_classes):\r\n",
        "  \"\"\"One-hot encode a sequence of tokens.\"\"\"\r\n",
        "  one_hot = np.zeros((len(seq), num_classes))\r\n",
        "  for i, item in enumerate(seq):\r\n",
        "    one_hot[i, item] = 1.\r\n",
        "  return one_hot"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuH7iXsj2Ww1",
        "outputId": "b3f97beb-ebcf-4f1a-ace4-e63bffa2e461"
      },
      "source": [
        "# One-hot encoding \r\n",
        "print (X_train[0])\r\n",
        "print (len(X_train[0]))\r\n",
        "cat = to_categorical(seq = X_train[0], num_classes = len(tokeniser))\r\n",
        "\r\n",
        "print (cat)\r\n",
        "print (cat.shape)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 16   1 285 142 114  24]\n",
            "6\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(6, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bkcutvt2rQP"
      },
      "source": [
        "# Convert tokens to one-hot\r\n",
        "\r\n",
        "vocab_size = len(tokeniser)\r\n",
        "X_train = [to_categorical(seq, num_classes = vocab_size) for seq in X_train]\r\n",
        "X_val = [to_categorical(seq, num_classes = vocab_size) for seq in X_val]\r\n",
        "X_test = [to_categorical(seq, num_classes = vocab_size) for seq in X_test]"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQQZ4P93Oy0"
      },
      "source": [
        "# Padding \r\n",
        "\r\n",
        "# - all the inputs have varying lengths, but each batch needs to e uniformly shaped\r\n",
        "# - we can use padding to make all the inputs in the batch the same length\r\n",
        "# - the padding index will be 0\r\n",
        "\r\n",
        "## ** one-hot encoding creates a batch of shape (N, max_seq_len, vocab_size) so we'll need to pad 3D sequences "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFz7Go4m30W3"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len = 0):\r\n",
        "  \"\"\"Pad sequences to max length in sequence.\"\"\"\r\n",
        "  max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\r\n",
        "  num_classes = sequences[0].shape[-1]\r\n",
        "  padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\r\n",
        "  for i, sequence in enumerate(sequences):\r\n",
        "    padded_sequences[i][:len(sequence)] = sequence\r\n",
        "  return padded_sequences"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHFOCr1H4rE_",
        "outputId": "21fca0f9-77f4-427c-a281-40b7a283f313"
      },
      "source": [
        "# 3D sequences \r\n",
        "\r\n",
        "print (X_train[0].shape, X_train[1].shape, X_train[2].shape)\r\n",
        "padded = pad_sequences(X_train[0:3])\r\n",
        "print (padded.shape)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 500) (5, 500) (6, 500)\n",
            "(3, 6, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFPyGyJ5CAT"
      },
      "source": [
        "# Dataset\r\n",
        "# - here we need to create datasets and dataloaders to be able to efficiently create batches with the data splits \r\n",
        "\r\n",
        "FILTER_SIZE = 1 # unigram"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTMezleJ6U7q"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self, X, y, max_filter_size):\r\n",
        "    self.X = X\r\n",
        "    self.y = y\r\n",
        "    self.max_filter_size = max_filter_size\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.y)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<Dataset(N = {len(self)})>\"\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    X = self.X[index]\r\n",
        "    y = self.y[index]\r\n",
        "    return [X, y]\r\n",
        "\r\n",
        "  def collate_fn(self, batch):\r\n",
        "    \"\"\"Processing on batch.\"\"\"\r\n",
        "    # Get inputs\r\n",
        "    X = np.array(batch, dtype = object)[:, 0]\r\n",
        "    y = np.stack(np.array(batch, dtype = object)[:, 1], axis = 0)\r\n",
        "\r\n",
        "    # Pad sequences \r\n",
        "    X = pad_sequences(X, max_seq_len = self.max_filter_size)\r\n",
        "\r\n",
        "    # Cast\r\n",
        "    X = torch.FloatTensor(X.astype(np.int32))\r\n",
        "    y = torch.LongTensor(y.astype(np.int32))\r\n",
        "\r\n",
        "    return X, y\r\n",
        "\r\n",
        "  def create_dataloader(self, batch_size, shuffle = False, drop_last = False):\r\n",
        "    return torch.utils.data.DataLoader(\r\n",
        "        dataset = self, batch_size = batch_size, collate_fn = self.collate_fn, \r\n",
        "        shuffle = shuffle, drop_last = drop_last, pin_memory = True)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXoY27PZ8Q5u",
        "outputId": "14747b0e-c3cf-43b8-ede0-4933deb64051"
      },
      "source": [
        "# Create datasets for embedding \r\n",
        "\r\n",
        "train_dataset = Dataset(X = X_train, y = y_train, max_filter_size = FILTER_SIZE)\r\n",
        "val_dataset = Dataset(X = X_val, y = y_val, max_filter_size = FILTER_SIZE)\r\n",
        "test_dataset = Dataset(X = X_test, y = y_test, max_filter_size = FILTER_SIZE)\r\n",
        "print (\"Datasets: \\n\"\r\n",
        "    f\" Train dataset: {train_dataset.__str__()}\\n\"\r\n",
        "    f\" Val dataset: {val_dataset.__str__()}\\n\"\r\n",
        "    f\" Test dataset: {test_dataset.__str__()}\\n\"\r\n",
        "    \"Sample Point: \\n\"\r\n",
        "    f\" X: {test_dataset[0][0]}\\n\"\r\n",
        "    f\" y: {test_dataset[0][1]}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets: \n",
            " Train dataset: <Dataset(N = 84000)>\n",
            " Val dataset: <Dataset(N = 18000)>\n",
            " Test dataset: <Dataset(N = 18000)>\n",
            "Sample Point: \n",
            " X: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            " y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En480uM4-uS7",
        "outputId": "fe96540d-9c80-41d7-f978-fc4f6cd44adf"
      },
      "source": [
        "# Create dataloaders \r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "batch_X, batch_y = next(iter(test_dataloader))\r\n",
        "print (\"Sample batch:\\n\"\r\n",
        "    f\" X: {list(batch_X.size())}\\n\"\r\n",
        "    f\" y: {list(batch_y.size())}\\n\"\r\n",
        "    \"Sample point:\\n\"\r\n",
        "    f\" X: {batch_X[0]}\\n\"\r\n",
        "    f\" y: {batch_y[0]}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            " X: [64, 14, 500]\n",
            " y: [64]\n",
            "Sample point:\n",
            " X: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cpu')\n",
            " y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3T_oqa4DcoL"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}