{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: Linear Regression ",
      "provenance": [],
      "authorship_tag": "ABX9TyPpX/mh0Hl5sgvo9+o3x6mc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jhus7YXztS9o"
      },
      "source": [
        "## Understanding linear regression, the math, NumPy and PyTorch implementation \r\n",
        "\r\n",
        "# y = XW + b (linear model)\r\n",
        "\r\n",
        "# where y is the prediction, X is the input(s), W is the weight and b is the bias"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lt3KwLZQWHvH"
      },
      "source": [
        "# the objective is to use the input X to predict the output y using a linear model.\r\n",
        "# the model will be a line of best fit that minimises the distance between the predicted (model output) and the target (ground truth) values \r\n",
        "\r\n",
        "# Training data (X, y) is used to train the model and learn the weights W using gradient descent."
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2hEOiSdWnmf"
      },
      "source": [
        "# Generating the data\r\n",
        "\r\n",
        "# - for this exercise, we will generate some dummy data to apply linear regression on. \r\n",
        "# - it will create roughly linear data (y = 3.5x + noise)\r\n",
        "# - the random noise will be added to create realistic data that doesn't perfectly align in a line.\r\n",
        "# - there will be slight variance since we added some noise "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsBIA_YlXN4d",
        "outputId": "8430c546-dc79-4463-c1e1-fc09b7554710"
      },
      "source": [
        "# Importing the necessary libraries \r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd \r\n",
        "import matplotlib.pyplot as plt\r\n",
        "print (\"Libraries successfully imported\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Libraries successfully imported\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FTYLonQrXe1z"
      },
      "source": [
        "# set seed for reproducibility \r\n",
        "SEED = 1234\r\n",
        "NUM_SAMPLES = 50\r\n",
        "\r\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bntHexWeXsQ_"
      },
      "source": [
        "# Generating dummy data\r\n",
        "\r\n",
        "def generate_data(num_samples):\r\n",
        "  \"\"\"Generate dummy data for linear regression\"\"\"\r\n",
        "  X = np.array(range(num_samples))\r\n",
        "  random_noise = np.random.uniform(-10,20,size = num_samples)\r\n",
        "  y = 3.5 * X + random_noise # add some noise\r\n",
        "  return X, y"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBeaC_GUYY6h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bff2da4-ce06-4f44-ed92-5f3f4c990644"
      },
      "source": [
        "# Generate random (linear) data\r\n",
        "\r\n",
        "X, y = generate_data(num_samples = NUM_SAMPLES)\r\n",
        "data = np.vstack([X, y]).T\r\n",
        "print (data[:5])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.         -4.25441649]\n",
            " [ 1.         12.16326313]\n",
            " [ 2.         10.13183217]\n",
            " [ 3.         24.06075751]\n",
            " [ 4.         27.39927424]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "4byZ4RdscYJs",
        "outputId": "777bb47a-e0ad-42cc-8744-5c4629f91f4b"
      },
      "source": [
        "# Loading data into the Pandas DataFrame\r\n",
        "\r\n",
        "df = pd.DataFrame(data, columns = [\"X\", \"y\"])\r\n",
        "X = df[[\"X\"]].values\r\n",
        "y = df[[\"y\"]].values\r\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>X</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-4.254416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>12.163263</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2.0</td>\n",
              "      <td>10.131832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3.0</td>\n",
              "      <td>24.060758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>27.399274</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     X          y\n",
              "0  0.0  -4.254416\n",
              "1  1.0  12.163263\n",
              "2  2.0  10.131832\n",
              "3  3.0  24.060758\n",
              "4  4.0  27.399274"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "JPPeCW0Ac0FK",
        "outputId": "2a1048fa-263a-4adc-f0cb-d4daf9d7b5d1"
      },
      "source": [
        "# Making a scatter plot \r\n",
        "plt.title(\"Generated data\")\r\n",
        "plt.scatter(x = df[\"X\"], y = df[\"y\"])\r\n",
        "plt.show()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOKxe8OYdrpp"
      },
      "source": [
        "## Numpy implementation \r\n",
        "# - Splitting the data \r\n",
        "# -- Here, we will randomly split the dataset into three sets: train, validation and test data\r\n",
        "# train - used to train the model \r\n",
        "# val - used to validate models performance during training \r\n",
        "# test - used to evaluate the fully trained model"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7XBUha_vgrf5"
      },
      "source": [
        "TRAIN_SIZE = 0.7\r\n",
        "VAL_SIZE = 0.15\r\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oj18BNGYh8uj"
      },
      "source": [
        "# Shuffling the data \r\n",
        "# be care not to shuffle X and y separately because then the inputs will not correspond to the outputs\r\n",
        "\r\n",
        "indices = list(range(NUM_SAMPLES))\r\n",
        "np.random.shuffle(indices)\r\n",
        "\r\n",
        "X = X[indices]\r\n",
        "y = y[indices]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJbKie78iOrl"
      },
      "source": [
        "# Split indices \r\n",
        "\r\n",
        "train_start = 0\r\n",
        "train_end = int(0.7 * NUM_SAMPLES)\r\n",
        "val_start = train_end\r\n",
        "val_end = int((TRAIN_SIZE + VAL_SIZE) * NUM_SAMPLES)\r\n",
        "test_start = val_end"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qK8nYPU-j7xS",
        "outputId": "339c2a7c-036b-4b77-89bb-3a974243ddb7"
      },
      "source": [
        "# Splitting data \r\n",
        "\r\n",
        "X_train = X[train_start:train_end]\r\n",
        "y_train = y[train_start:train_end]\r\n",
        "\r\n",
        "X_val = X[val_start:val_end]\r\n",
        "y_val = y[val_start:val_end]\r\n",
        "\r\n",
        "X_test = X[test_start:]\r\n",
        "y_test = y[test_start:]\r\n",
        "\r\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\r\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (35, 1), y_train: (35, 1)\n",
            "X_val: (7, 1), y_val: (7, 1)\n",
            "X_test: (8, 1), y_test: (8, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMDakBznlGKJ"
      },
      "source": [
        "# Standardising the data\r\n",
        "# - this implies making it have a zero mean and unit magnitude such that the magnitude of a specific feature will not affect how the model learns its weights.\r\n",
        "\r\n",
        "# Using the formular (standardised value = (inputs - mean)/standard deviation)\r\n",
        "\r\n",
        "def standardise_data(data, mean, std):\r\n",
        "  return(data - mean)/std"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tp4bnwG1l9NB",
        "outputId": "6d28169e-2d82-4e51-d956-96224bba57ae"
      },
      "source": [
        "# Determining the means and the stds \r\n",
        "# We need to treat the validation and test datasets as it they are hidden \r\n",
        "# - So we only use the train set to determing the mean and std to avoid biasing the training process\r\n",
        "\r\n",
        "X_mean = np.mean(X_train)\r\n",
        "X_std = np.std(X_train)\r\n",
        "y_mean = np.mean(y_train)\r\n",
        "y_std = np.std(y_train)\r\n",
        "\r\n",
        "print (X_mean, X_std, y_mean, y_std)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "23.742857142857144 14.263525625360167 90.0159460487698 49.02826239495899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O9RHzC_mnqm"
      },
      "source": [
        "# Standardise \r\n",
        "\r\n",
        "X_train = standardise_data(X_train, X_mean, X_std)\r\n",
        "y_train = standardise_data(y_train, y_mean, y_std)\r\n",
        "\r\n",
        "X_val = standardise_data(X_val, X_mean, X_std)\r\n",
        "y_val = standardise_data(y_val, y_mean, y_std)\r\n",
        "\r\n",
        "X_test = standardise_data(X_test, X_mean, X_std)\r\n",
        "y_test = standardise_data(y_test, y_mean, y_std)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RNHTZOeko1Bl",
        "outputId": "7b774417-2a72-4c52-f6da-a58e8bdcdc28"
      },
      "source": [
        "# Check (mean should be approx 0 and std should be approx 1)\r\n",
        "\r\n",
        "print (f\"mean: {np.mean(X_test, axis = 0)[0]:.1f}, std: {np.std(X_test, axis = 0)[0]:.1f}\")\r\n",
        "print (f\"mean: {np.mean(y_test, axis = 0)[0]:.1f}, std: {np.std(y_test, axis = 0)[0]:.1f}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: 0.9, std: 0.5\n",
            "mean: 0.8, std: 0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hVlomDzpwKI"
      },
      "source": [
        "# Weights \r\n",
        "# the goal is to learn a linear model that predicts y given X using weights W and bias b\r\n",
        "\r\n",
        "# Step 1 - Randomly initialise the models weights W\r\n",
        "\r\n",
        "INPUT_DIM = X_train.shape[1] # X is 1-dimensional\r\n",
        "OUTPUT_DIM = y_train.shape[1] # y is 1-dimensional"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnZdXK-0rHmP",
        "outputId": "a1181327-e9e6-4a72-87d3-3baa07a1b22a"
      },
      "source": [
        "# Initialise random weights \r\n",
        "\r\n",
        "W = 0.01 * np.random.randn(INPUT_DIM, OUTPUT_DIM)\r\n",
        "b = np.zeros((1,1))\r\n",
        "\r\n",
        "print (f\"W: {W.shape}\")\r\n",
        "print (f\"b: {b.shape}\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W: (1, 1)\n",
            "b: (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ghUBhR5Ere4p",
        "outputId": "24882d88-7441-420d-a683-fd6056c597bf"
      },
      "source": [
        "# Model \r\n",
        "# Step 2 - feed inputs X into the model to receive predictions y\r\n",
        "\r\n",
        "# Forward pass [NX1] * [1X1] = [NX1]\r\n",
        "\r\n",
        "y_pred = np.dot(X_train, W) + b\r\n",
        "\r\n",
        "print (f\"y_pred: {y_pred.shape}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_pred: (35, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHVnUA3ZsBkP",
        "outputId": "259eefa9-5500-4c02-91d4-946fe6e5ea32"
      },
      "source": [
        "# Loss \r\n",
        "# Step 3 -  compare predictions y wiht the actual target values y using the objective (cost) function to determne the loss J.\r\n",
        "# - A common objective function for linear regression is the mean squarred error (MSE)\r\n",
        "# - this function calculates the difference between the predicted and the target values and squares it\r\n",
        "\r\n",
        "N = len(y_train)\r\n",
        "loss = (1/N) * np.sum((y_train - y_pred) ** 2)\r\n",
        "\r\n",
        "print (f\"loss: {loss:.2f}\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss: 0.98\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpI4GPDhsslp",
        "outputId": "0f989bdc-1fc4-424b-819f-04fc68073dff"
      },
      "source": [
        "# Gradients \r\n",
        "# Step 4 - calculate the gradient of the loss w.r.t the models weights \r\n",
        "# - the gradient is a derivative or the rate of change of a function. \r\n",
        "# - it is a vector that points in the direction of greatest increase of a function. \r\n",
        "# - For e.g, the gradient of our loss function (J) w.r.t the weights (W) will inform how to change W so we can maximise J\r\n",
        "# - However, we want to minimise the loss so we subtract the gradient from W\r\n",
        "\r\n",
        "# Backpropagation \r\n",
        "\r\n",
        "dW = -(2/N) * np.sum((y_train - y_pred) * X_train)\r\n",
        "db = -(2/N) * np.sum((y_train - y_pred) * 1)\r\n",
        "\r\n",
        "print (dW, db)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-1.9551728358043143 -7.612957883143931e-17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAYYELvjw8Yz"
      },
      "source": [
        "# Update weights \r\n",
        "# Step 5 - Update the weights using a small learning rate alpha*\r\n",
        "# - the learning rate is a way to control how much we update the weights by. \r\n",
        "# - choosing a small learning rate means a longer time for the model to train \r\n",
        "# - choosing a large learning rate could lead to an overshoot and the traing may never converge\r\n",
        "# the specific learning rate depends on the data and the type of model being used.\r\n",
        "# typically, learning rate ranges around 1e-8 to 1e-1\r\n",
        "\r\n",
        "LEARNING_RATE = 1e-1"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AX-IcGJxOhF"
      },
      "source": [
        "# Update weight -- \r\n",
        "W += - LEARNING_RATE * dW\r\n",
        "b += - LEARNING_RATE * db"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tG_iuB5fxb63"
      },
      "source": [
        "# Training \r\n",
        "# Step 6 - Repeat steps 2 - 5 to minimise the loss and train the model\r\n",
        "\r\n",
        "NUM_EPOCHS = 100"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZtPkGK2ySMc"
      },
      "source": [
        "# Initialise "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}