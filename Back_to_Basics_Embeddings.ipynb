{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: Embeddings",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM2I9PhoYvL0ujRnIiB1b8k",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_Embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSiBz5ORdbyn"
      },
      "source": [
        "# Embeddings \r\n",
        "# - these are capable of capturing the contextual, semantic and syntatic meaning in data.\r\n",
        "\r\n",
        "# While one-hot encoding allows us to preserve the structural info, it has two disadvantages \r\n",
        "# 1. linearly dependent on the number of unique token in the vocab which is problem if we have a large corpus\r\n",
        "# 2. the representation for each token does not preserve any relationship with respect to other tokens\r\n",
        "\r\n",
        "# Embeddings address the short comings of one-hot encoding\r\n",
        "# - its main idea is to have fixed length representations for the tokens in a text regardless of the tokens in the vocab\r\n",
        "# with one-hot encoding, each token is represented by an array of size vocab size but with embeddings, each token now has the shape embed dim\r\n",
        "###- the values in the rep are not fixed binary values but rather changing floating points allowing for fine-grained learned reps\r\n",
        "\r\n",
        "# the objective here is to rep tokens in text that capture the intrinsic semantic relationships\r\n",
        "## leveraging the low-dimensionality while capturing relationships and interpretable token reps."
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jhvs0QObfR5u",
        "outputId": "faf7c97d-b164-4bb7-9310-7860daf62a20"
      },
      "source": [
        "# Learning Embeddings \r\n",
        "# - We can learn embeddings by creating our model in PyTorch, but first, we're going to use a library that specialises in embeddings and topic modelling called Gensim\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('punkt');\r\n",
        "import numpy as np\r\n",
        "import re\r\n",
        "import urllib"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQot3XjrfxM_"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU7tcZAXf8Ff"
      },
      "source": [
        "# Set seed for reproducibility \r\n",
        "\r\n",
        "np.random.seed(SEED)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9KVbUSxgA91",
        "outputId": "4ad66d0f-e0df-4595-a7f3-89b994cdf2bc"
      },
      "source": [
        "# Split text into sentences \r\n",
        "\r\n",
        "tokeniser = nltk.data.load(\"tokenizers/punkt/english.pickle\")\r\n",
        "book = urllib.request.urlopen(url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/harrypotter.txt\")\r\n",
        "sentences = tokeniser.tokenize(str(book.read()))\r\n",
        "print (f\"{len(sentences)} sentences\")"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12443 sentences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zpt221jgv4w"
      },
      "source": [
        "def preprocess(text):\r\n",
        "  \"\"\"Conditional preprocessing on our text.\"\"\"\r\n",
        "  # Lower\r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric characters \r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces\r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  # Separate into word tokens\r\n",
        "  text = text.split(\" \")\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHlGfLTmh5vH",
        "outputId": "1308c81f-a6d7-44b6-9d1e-d1b1bc79cb69"
      },
      "source": [
        "# Preprocess sentences\r\n",
        "print (sentences[11])\r\n",
        "sentences = [preprocess(sentence) for sentence in sentences]\r\n",
        "print (sentences[11])"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Snape nodded, but did not elaborate.\n",
            "['snape', 'nodded', 'but', 'did', 'not', 'elaborate']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BjvvySmmiPEz"
      },
      "source": [
        "# How doe we learn the embeddings in the first place?\r\n",
        "# The intuition behind embeddins is that the definition of a token depends NOT on the token itself, but on its context.\r\n",
        "# - There are several ways of doing this. \r\n",
        "# -- given the word in context, predict the target word (CBOW - continous bag of words)\r\n",
        "# -- given the target word, predict the context word (skip-gram)\r\n",
        "# -- given a sequence of words, predict the next word(LM - language modelling)\r\n",
        "\r\n",
        "# all these approaches involve the creation of data to train the model on. \r\n",
        "# Every word in a sentence becomes the target word and the context words are determined by a window\r\n",
        "# we repeat this for every sentence in the corpus and this results in the training data for unsupervised taskk\r\n",
        "\r\n",
        "# the idea is that similar target words will appear with similar contexts and we can learn this relationship by repeatedly training our model (wiht context and target) pairs"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "450GRspwiZcU"
      },
      "source": [
        "# Word2Vec\r\n",
        "\r\n",
        "# working with large vocabs to learn embeddings can become complicated quickly\r\n",
        "# Here, we can use the \"negative sampling\", which only updates the correct class and a few arbitrary incorrect classes \r\n",
        "# We can do this because of the large amoutn of training data where we will see the same word as the target class multiple times\r\n",
        "\r\n",
        "import gensim\r\n",
        "from gensim.models import KeyedVectors\r\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qup89Kc8lYFA"
      },
      "source": [
        "EMBEDDING_DIM = 100\r\n",
        "WINDOW = 5\r\n",
        "MIN_COUNT = 3 # ignores all the words with total frequency lower than this\r\n",
        "SKIP_GRAM = 1 # 0 = CBOW\r\n",
        "NEGATIVE_SAMPLING = 20"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcJuTmY3lqkf",
        "outputId": "b9d81a22-9c77-4864-c472-c85694de4870"
      },
      "source": [
        "# super fast because of optimised C code under the hood\r\n",
        "\r\n",
        "w2v = Word2Vec(sentences = sentences, size = EMBEDDING_DIM, window = WINDOW,\r\n",
        "               min_count = MIN_COUNT, sg = SKIP_GRAM, negative = NEGATIVE_SAMPLING)\r\n",
        "print (w2v)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word2Vec(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tKBOHpTxmEJc",
        "outputId": "67a9bb11-6759-426a-cdd1-9cdf78843f2d"
      },
      "source": [
        "# Vector for each word\r\n",
        "w2v.wv.get_vector(\"potter\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.01697466, -0.2866405 , -0.3008265 , -0.29403865, -0.22781292,\n",
              "       -0.19741872, -0.0874659 ,  0.14124094,  0.58748853,  0.33553848,\n",
              "       -0.240756  , -0.04006175, -0.13412021,  0.17894153, -0.14883168,\n",
              "       -0.34405807,  0.27631482,  0.26866025, -0.5066555 ,  0.14108138,\n",
              "       -0.13761571, -0.3687644 , -0.06418797,  0.18793695, -0.2570797 ,\n",
              "        0.35075605,  0.13261083,  0.17419575, -0.05647279, -0.07211813,\n",
              "        0.59689295,  0.55984116, -0.01833745, -0.45927507, -0.34138373,\n",
              "       -0.0491113 ,  0.37332585, -0.3035386 , -0.4004415 , -0.06110671,\n",
              "       -0.00195717, -0.10445888, -0.28035152, -0.16219528,  0.2807279 ,\n",
              "        0.41262493,  0.0014628 , -0.35501745,  0.22529054, -0.25333297,\n",
              "        0.11366666,  0.25780088,  0.03564634,  0.04202371,  0.02636017,\n",
              "        0.04561004,  0.42189986,  0.01397108,  0.2692497 , -0.26579332,\n",
              "       -0.0788378 , -0.10421843, -0.23964319,  0.12406243,  0.17855582,\n",
              "        0.21702808, -0.31919608,  0.46681818, -0.22580583, -0.1442215 ,\n",
              "       -0.17711951, -0.31193984, -0.01348422, -0.1102741 ,  0.03378719,\n",
              "        0.18260476,  0.2524181 ,  0.16969748, -0.26153752, -0.05052852,\n",
              "        0.32046553, -0.17907579,  0.11205264, -0.50996053, -0.05544428,\n",
              "       -0.22829317, -0.11102615,  0.20979883, -0.08993088,  0.18029413,\n",
              "       -0.03732749, -0.24287714,  0.08354235, -0.20608968,  0.01449588,\n",
              "        0.15598959,  0.2703404 ,  0.11156769, -0.30567735, -0.08815683],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fXaF0SnmuzX",
        "outputId": "2ee5f487-6575-41ae-9cfe-d363e13363c7"
      },
      "source": [
        "# Get nearest neighbours (excluding itself)\r\n",
        "\r\n",
        "w2v.wv.most_similar(positive = \"scar\", topn = 5)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('forehead', 0.9274433255195618),\n",
              " ('pain', 0.9227378368377686),\n",
              " ('mouth', 0.9116102457046509),\n",
              " ('prickling', 0.9068350195884705),\n",
              " ('heart', 0.8966714143753052)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5RNaihm9sk"
      },
      "source": [
        "# Saving and loading \r\n",
        "\r\n",
        "w2v.wv.save_word2vec_format(\"model.bin\", binary = True)\r\n",
        "w2v = KeyedVectors.load_word2vec_format(\"model.bin\", binary = True)"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcmQyBXHnVxx"
      },
      "source": [
        "# FastText\r\n",
        "\r\n",
        "# What happens if a word doesnt exist in the vocab?\r\n",
        "# We could assign an \"UNK\" (unkown) token which is used for all OOV (out of vocab) words or we could use FastText, which uses character-level n-grams to embed a word\r\n",
        "# This helps embed rare words, misspelled words and also words that don't exist in our corpus but are similar to words in our corpus"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VeI_6Qy-oE8W"
      },
      "source": [
        "from gensim.models import FastText"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4GHCas5oJD0",
        "outputId": "67f63031-3d30-499f-cdcf-605ada3a0b19"
      },
      "source": [
        "# super fast because of the optimised C code under the hood\r\n",
        "\r\n",
        "ft = FastText(sentences = sentences, size = EMBEDDING_DIM, window = WINDOW, \r\n",
        "              min_count = MIN_COUNT, sg = SKIP_GRAM, negative = NEGATIVE_SAMPLING)\r\n",
        "print (ft)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FastText(vocab=4937, size=100, alpha=0.025)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt2OJ2IeojP_"
      },
      "source": [
        "# This word doesn't 'exist so the word2vec model will error out \r\n",
        "\r\n",
        "# w2v.wv.most_similar(positive = \"scarring\", topn = 5) # uncomment to check"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c61VZl78o5Z6",
        "outputId": "6f41c9f2-79f2-464e-d867-b83c514479b3"
      },
      "source": [
        "# FastText on the other hand will use n-grams to embed an OOV word\r\n",
        "\r\n",
        "ft.wv.most_similar(positive = \"scarring\", topn = 10)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('prickling', 0.9862031936645508),\n",
              " ('shuddering', 0.982107937335968),\n",
              " ('heartstring', 0.9814382791519165),\n",
              " ('brandishing', 0.9805978536605835),\n",
              " ('rippling', 0.9801949858665466),\n",
              " ('muffling', 0.980065107345581),\n",
              " ('shimmering', 0.9799435138702393),\n",
              " ('crumbling', 0.9794167280197144),\n",
              " ('shivering', 0.9788283109664917),\n",
              " ('compressing', 0.9781619310379028)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEC-9GUXpOug"
      },
      "source": [
        "# Save and load \r\n",
        "\r\n",
        "ft.wv.save(\"model.bin\")\r\n",
        "ft = KeyedVectors.load(\"model.bin\")"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxT2aaCEskm7"
      },
      "source": [
        "# Pretrained embeddings\r\n",
        "\r\n",
        "# - we can learn embeddings from scratch as above but we can also leverage pretrained embeddings that have been trained on millions of docs. \r\n",
        "# Popular ones include Word2Vec (skip gram) or GloVe(global word word co-occurence)\r\n",
        "# we can validate that these embeddings captured meaningful semantic relationships by confirming them \r\n",
        "\r\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\r\n",
        "from io import BytesIO\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.decomposition import PCA\r\n",
        "from urllib.request import urlopen\r\n",
        "from zipfile import ZipFile"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euO10XHmueBe"
      },
      "source": [
        "# Arguments \r\n",
        "\r\n",
        "EMBEDDING_DIM = 100"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hj6gxJZvgwy"
      },
      "source": [
        "def plot_embeddings(words, embeddings, pca_results):\r\n",
        "  for word in words:\r\n",
        "    index = embeddings.index2word.index(word)\r\n",
        "    plt.scatter(pca_results[index, 0], pca_results[index, 1])\r\n",
        "    plt.annotate(word, xy = (pca_results[index, 0], pca_results[index, 1]))\r\n",
        "  plt.show()"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0jZYCLNwRXe",
        "outputId": "4e082f44-e1bf-47a3-e4bd-5861807fa090"
      },
      "source": [
        "# Unzip the file (may a while)\r\n",
        "\r\n",
        "resp = urlopen(\"http://nlp.stanford.edu/data/glove.6B.zip\")\r\n",
        "zipfile = ZipFile(BytesIO(resp.read()))\r\n",
        "zipfile.namelist()"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['glove.6B.50d.txt',\n",
              " 'glove.6B.100d.txt',\n",
              " 'glove.6B.200d.txt',\n",
              " 'glove.6B.300d.txt']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bP9SIfy_-i7A",
        "outputId": "b7046fb5-403c-4e57-d081-8395216a348b"
      },
      "source": [
        "# Write embeddings to file \r\n",
        "\r\n",
        "embeddings_file = \"glove.6B.{0}d.txt\".format(EMBEDDING_DIM)\r\n",
        "zipfile.extract(embeddings_file)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/glove.6B.100d.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4zfsK7l-zz2",
        "outputId": "b9c0d75b-a885-497d-973e-4a77a4803c43"
      },
      "source": [
        "# Preview of the GloVe embeddings file \r\n",
        "\r\n",
        "with open(embeddings_file, \"r\") as fp:\r\n",
        "  line = next(fp)\r\n",
        "  values = line.split()\r\n",
        "  word = values[0]\r\n",
        "  embedding = np.asarray(values[1:], dtype = \"float32\")\r\n",
        "  print (f\"word: {word}\")\r\n",
        "  print (f\"embedding:\\n{embedding}\")\r\n",
        "  print (f\"embedding dim: {len(embedding)}\")"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "word: the\n",
            "embedding:\n",
            "[-0.038194 -0.24487   0.72812  -0.39961   0.083172  0.043953 -0.39141\n",
            "  0.3344   -0.57545   0.087459  0.28787  -0.06731   0.30906  -0.26384\n",
            " -0.13231  -0.20757   0.33395  -0.33848  -0.31743  -0.48336   0.1464\n",
            " -0.37304   0.34577   0.052041  0.44946  -0.46971   0.02628  -0.54155\n",
            " -0.15518  -0.14107  -0.039722  0.28277   0.14393   0.23464  -0.31021\n",
            "  0.086173  0.20397   0.52624   0.17164  -0.082378 -0.71787  -0.41531\n",
            "  0.20335  -0.12763   0.41367   0.55187   0.57908  -0.33477  -0.36559\n",
            " -0.54857  -0.062892  0.26584   0.30205   0.99775  -0.80481  -3.0243\n",
            "  0.01254  -0.36942   2.2167    0.72201  -0.24978   0.92136   0.034514\n",
            "  0.46745   1.1079   -0.19358  -0.074575  0.23353  -0.052062 -0.22044\n",
            "  0.057162 -0.15806  -0.30798  -0.41625   0.37972   0.15006  -0.53212\n",
            " -0.2055   -1.2526    0.071624  0.70565   0.49744  -0.42063   0.26148\n",
            " -1.538    -0.30223  -0.073438 -0.28312   0.37104  -0.25217   0.016215\n",
            " -0.017099 -0.38984   0.87424  -0.72569  -0.51058  -0.52028  -0.1459\n",
            "  0.8278    0.27062 ]\n",
            "embedding dim: 100\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57wk9nMK_ezh",
        "outputId": "a6f92b6a-3bca-4aaf-b2f4-c8de8418b105"
      },
      "source": [
        "# Save GloVe embeddings to local directory in word2vec format\r\n",
        "\r\n",
        "word2vec_output_file = \"{0}.word2vec\".format(embeddings_file)\r\n",
        "glove2word2vec(embeddings_file, word2vec_output_file)"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400000, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF1aCx4J_4VW"
      },
      "source": [
        "# Load embeddings (may take a while)\r\n",
        "\r\n",
        "glove = KeyedVectors.load_word2vec_format(word2vec_output_file, binary = False)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XbrBj9ZBAWvr",
        "outputId": "ad3e9bdc-b4a4-4a6a-ec12-1805b9c71784"
      },
      "source": [
        "# (king - man) + woman = ?\r\n",
        "\r\n",
        "glove.most_similar(positive = [\"woman\", \"king\"], negative = [\"man\"], topn = 5)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('queen', 0.7698541283607483),\n",
              " ('monarch', 0.6843380928039551),\n",
              " ('throne', 0.6755735874176025),\n",
              " ('daughter', 0.6594556570053101),\n",
              " ('princess', 0.6520534753799438)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nRSrgpJVBVpA",
        "outputId": "a83a5f25-643c-4c53-9999-8673fd476912"
      },
      "source": [
        "# Get nearest neighbours (excluding itself)\r\n",
        "\r\n",
        "glove.wv.most_similar(positive = \"goku\", topn = 5)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('gohan', 0.7246542572975159),\n",
              " ('bulma', 0.6497020125389099),\n",
              " ('raistlin', 0.6443604230880737),\n",
              " ('skaar', 0.6316742897033691),\n",
              " ('guybrush', 0.6231324672698975)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4wldVzSLBiLD",
        "outputId": "f8c31103-1665-445b-9d1d-a7f9091e979e"
      },
      "source": [
        "# Reduce dimensionality for plotting\r\n",
        "\r\n",
        "X = glove[glove.wv.vocab]\r\n",
        "pca = PCA(n_components = 2)\r\n",
        "pca_results = pca.fit_transform(X)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "_ln19cDxByqT",
        "outputId": "6158c609-94ef-4bbb-d97e-d47e37722929"
      },
      "source": [
        "# Visualise \r\n",
        "\r\n",
        "plot_embeddings(words = [\"king\", \"queen\", \"man\", \"woman\"], \r\n",
        "                embeddings = glove, pca_results = pca_results)"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Wht5-zcCIcu",
        "outputId": "4140f693-de50-44c7-84f0-e32405605ec5"
      },
      "source": [
        "# Bias in embeddings \r\n",
        "\r\n",
        "glove.most_similar(positive = [\"woman\", \"doctor\"], negative = [\"man\"], topn = 5)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nurse', 0.7735227346420288),\n",
              " ('physician', 0.7189429998397827),\n",
              " ('doctors', 0.6824328303337097),\n",
              " ('patient', 0.6750682592391968),\n",
              " ('dentist', 0.6726033687591553)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmiecZFuGMJx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}