{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: CNNs",
      "provenance": [],
      "authorship_tag": "ABX9TyOywIEDcpISowLZF0Js8I4V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSEYD28OfPkb"
      },
      "source": [
        "## Set up \r\n",
        "\r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import random \r\n",
        "import torch \r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759r6mk1ZUM_"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MqZJHqAZV1x"
      },
      "source": [
        "def set_seeds(seed = 1234):\r\n",
        "  \"\"\"Set seed for reproducibility.\"\"\"\r\n",
        "  np.random.seed(seed)\r\n",
        "  random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed_all(seed) # multi GPU"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP0JoHAEZ2XM"
      },
      "source": [
        "# Set seed for reproducibility \r\n",
        "\r\n",
        "set_seeds(seed=SEED)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWPpxlKIawys",
        "outputId": "5732edac-d984-401f-b595-4f82618692eb"
      },
      "source": [
        "# Set device \r\n",
        "\r\n",
        "cuda = True\r\n",
        "device = torch.device(\"cuda\" if (\r\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\r\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\r\n",
        "if device.type == \"cuda\":\r\n",
        "  torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\r\n",
        "print (device)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "hNTtW2TjbX90",
        "outputId": "a68b4e8d-4699-46fc-fd43-cafeec83519c"
      },
      "source": [
        "# Load data \r\n",
        "# - corpus of news article from http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html \r\n",
        "\r\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/news.csv\"\r\n",
        "df = pd.read_csv(url, header = 0) # load\r\n",
        "df = df.sample(frac = 1).reset_index(drop = True) # shuffle\r\n",
        "df.head()"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NlO6lmtb5rN"
      },
      "source": [
        "# Preprocessing \r\n",
        "# - to clean up the data, convert to lower text, remove filler words and filter using regex.\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "import re"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDTD_WxOcgyF",
        "outputId": "556c833e-4980-47bf-a7a8-c94dcfe0fa5b"
      },
      "source": [
        "nltk.download(\"stopwords\")\r\n",
        "STOPWORDS = stopwords.words(\"english\")\r\n",
        "print (STOPWORDS[:5])\r\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0oH6OeZdQld"
      },
      "source": [
        "def preprocess(text, stopwords = STOPWORDS):\r\n",
        "  \"\"\"Conditional preprocessing on our text unique to the task.\"\"\"\r\n",
        "  # Lower \r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Remove stopwords\r\n",
        "  pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\r\n",
        "  text = pattern.sub(\" \", text)\r\n",
        "\r\n",
        "  # Remove words in parenthesis\r\n",
        "  text = re.sub(r\"\\([^)]*\\)\", \" \", text)\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric characters\r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces \r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K-DBYnbtgJXf",
        "outputId": "d5d0b514-0abe-45b5-ca0f-bb3828a0456b"
      },
      "source": [
        "# Sample \r\n",
        "\r\n",
        "text = \"Great week for the NYSE\"\r\n",
        "preprocess(text = text)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVH3XrNgmJk",
        "outputId": "9e5e6946-fa36-4e65-b88b-bf26e94dacd4"
      },
      "source": [
        "# Apply to dataframe\r\n",
        "\r\n",
        "preprocessed_df = df.copy()\r\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\r\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TLGqCnLhMJL"
      },
      "source": [
        "# if you have preprocessing steps like standardisation, that are calculated, you need to separate the training an dtest set first before applying those operations. \r\n",
        "# this is because we cannot apply any knowledge gained from the test set accidentally (data leak during preprocessing/training). \r\n",
        "# - for global preprocessing steps like the functin above, where we arent learning anything from the data itself, we can perform them before splitting the data."
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvGalMXshdP5"
      },
      "source": [
        "# Split the data \r\n",
        "\r\n",
        "import collections\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2_5ayPKh7ak"
      },
      "source": [
        "TRAIN_SIZE = 0.7\r\n",
        "VAL_SIZE = 0.15\r\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToTVRdVRiu6m"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\r\n",
        "  \"\"\"Split dataset into data split.\"\"\"\r\n",
        "  X_train, X_, y_train, y_ = train_test_split(X, y, train_size = TRAIN_SIZE, stratify = y)\r\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size = 0.5, stratify = y_)\r\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dHEIRQjZoX"
      },
      "source": [
        "# Data\r\n",
        "X = preprocessed_df[\"title\"].values \r\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJxEUiLbjh4V",
        "outputId": "ebb93a76-f032-41cb-cd03-62f181f2f115"
      },
      "source": [
        "# Create data splits\r\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\r\n",
        "    X = X, y = y, train_size = TRAIN_SIZE)\r\n",
        "\r\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\r\n",
        "print (f\"X_train: {X_test.shape}, y_test: {y_test.shape}\")\r\n",
        "print (f\"Sample point: {X_train[0]} -> {y_train[0]}\")\r\n"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_train: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks -> World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtvU0BHUkSEr"
      },
      "source": [
        "# Label Encoding \r\n",
        "# to encode the text labels into unique indices\r\n",
        "\r\n",
        "import itertools"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2cewudKkgVY"
      },
      "source": [
        "class LabelEncoder(object):\r\n",
        "  \"\"\"Label encoder for tag labels.\"\"\"\r\n",
        "  def __init__(self, class_to_index = {}):\r\n",
        "    self.class_to_index = class_to_index\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.class_to_index)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<LabelEncoder(num_classes = {len(self)})>\"\r\n",
        "  \r\n",
        "  def fit(self, y):\r\n",
        "    classes = np.unique(y_train)\r\n",
        "    for i, class_ in enumerate(classes):\r\n",
        "      self.class_to_index[class_] = i\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "    return self\r\n",
        "\r\n",
        "  def encode(self, y):\r\n",
        "    encoded = np.zeros((len(y)), dtype = int)\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      encoded[i] = self.class_to_index[item]\r\n",
        "    return encoded\r\n",
        "\r\n",
        "  def decode(self, y):\r\n",
        "    classes = []\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      classes.append(self.index_to_class[item])\r\n",
        "    return classes\r\n",
        "\r\n",
        "  def save(self, fp):\r\n",
        "    with open(fp, \"w\") as fp:\r\n",
        "      contents = {\"class_to_index\": self.class_to_index}\r\n",
        "      json.dump(contents, fp, indent = 4, sort_keys = False)\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def load(cls, fp):\r\n",
        "    with open(fp, \"r\") as fp:\r\n",
        "      kwargs = json.load(fp = fp)\r\n",
        "    return cls(**kwargs)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwntyBauo_QA",
        "outputId": "28e752ce-ac64-4cf3-fdd4-e242de7e0641"
      },
      "source": [
        "# Encode \r\n",
        "\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "label_encoder.fit(y_train)\r\n",
        "NUM_CLASSES = len(label_encoder)\r\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHY1TClrpXP6",
        "outputId": "dc1ab4f3-49c2-4868-bc48-adf195731c36"
      },
      "source": [
        "# Converting labels to tokens \r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")\r\n",
        "\r\n",
        "y_train = label_encoder.encode(y_train)\r\n",
        "y_val = label_encoder.encode(y_val)\r\n",
        "y_test = label_encoder.encode(y_test)\r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFHTuNzTp3sq",
        "outputId": "a79d96c7-2166-4beb-e8cd-d3f5d0290af3"
      },
      "source": [
        "# Class weights \r\n",
        "\r\n",
        "counts = np.bincount(y_train)\r\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\r\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDrlCrFrD_3"
      },
      "source": [
        "# Tokenizer \r\n",
        "\r\n",
        "import json\r\n",
        "from collections import Counter\r\n",
        "from more_itertools import take"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFX9mkPwriDZ"
      },
      "source": [
        "class Tokeniser(object):\r\n",
        "  def __init__(self, char_level, num_tokens = None,\r\n",
        "               pad_token = \"<PAD>\", oov_token = \"<UNK>\", \r\n",
        "               token_to_index = None):\r\n",
        "    self.char_level = char_level\r\n",
        "    self.separator = \" \" if self.char_level else \" \"\r\n",
        "    if num_tokens: num_tokens -= 2 # pad + unk tokens\r\n",
        "    self.num_tokens = num_tokens\r\n",
        "    self.oov_token = oov_token\r\n",
        "    if not token_to_index:\r\n",
        "      token_to_index = {\"<PAD>\": 0, \"<UNK>\": 1}\r\n",
        "    self.token_to_index = token_to_index\r\n",
        "    self.index_to_token = {v: k for k, v in self.token_to_index.items()}\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.token_to_index)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<Tokeniser(num_tokens = {len(self)})>\"\r\n",
        "\r\n",
        "  def fit_on_texts(self, texts):\r\n",
        "    if self.char_level:\r\n",
        "      all_tokens = [token for text in texts for token in text]\r\n",
        "    if not self.char_level:\r\n",
        "      all_tokens = [token for text in texts for token in text.split(\" \")]\r\n",
        "    counts = Counter(all_tokens).most_common(self.num_tokens)\r\n",
        "    self.min_token_freq = counts[-1][1]\r\n",
        "    for token, count in counts:\r\n",
        "      index = len(self)\r\n",
        "      self.token_to_index[token] = index\r\n",
        "      self.index_to_token[index] = token\r\n",
        "    return self\r\n",
        "\r\n",
        "  def texts_to_sequence(self, texts):\r\n",
        "    sequences = []\r\n",
        "    for text in texts:\r\n",
        "      if not self.char_level:\r\n",
        "        text = text.split(' ')\r\n",
        "      sequence = []\r\n",
        "      for token in text: \r\n",
        "        sequence.append(self.token_to_index.get(\r\n",
        "            token, self.token_to_index[self.oov_token]))\r\n",
        "      sequences.append(np.asarray(sequence))\r\n",
        "    return sequences\r\n",
        "  \r\n",
        "  def sequences_to_texts(self, sequences):\r\n",
        "    texts = []\r\n",
        "    for sequence in sequences:\r\n",
        "      text = []\r\n",
        "      for index in sequence :\r\n",
        "        text.append(self.index_to_token.get(index, self.oov_token))\r\n",
        "      texts.append(self.separator.join([token for token in text]))\r\n",
        "    return texts\r\n",
        "  \r\n",
        "  def save(self, fp):\r\n",
        "    with open(fp, \"w\") as fp:\r\n",
        "      contents = {\r\n",
        "          \"char_level\": self.char_level, \r\n",
        "          \"oov_token\": self.oov_token, \r\n",
        "          \"token_to_index\": self.token_to_index\r\n",
        "      }\r\n",
        "      json.dump(contents, fp, indent = 4, sort_keys = False)\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def load(cls, fp):\r\n",
        "    with open(fp, \"r\") as fp:\r\n",
        "      kwargs = json.load(fp = fp)\r\n",
        "    return cls(**kwargs)"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cTZBh3bAwQUL"
      },
      "source": [
        "## - we will restrict the number of tokens in our tokenizer to the top 500 most frequent tokens (stop words already removed)\r\n",
        "# -- because the full vocabulary (approx 30k) is too large to run on google colab\r\n",
        "\r\n",
        "# ** it is important that we are only using the training data split because during inference, the model will not always know every token\r\n",
        "# -- so it is important to replicate that scenario with the validation and test split. "
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSQgaU3sxiWJ",
        "outputId": "3eb05a06-353a-47ef-e38f-289c9945a196"
      },
      "source": [
        "# Tokenise\r\n",
        "\r\n",
        "tokeniser = Tokeniser(char_level = False, num_tokens = 500)\r\n",
        "tokeniser.fit_on_texts(texts = X_train)\r\n",
        "VOCAB_SIZE = len(tokeniser)\r\n",
        "\r\n",
        "print (tokeniser)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<Tokeniser(num_tokens = 500)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCShuyiwyXQc",
        "outputId": "45755081-7a5f-4ef3-b651-03e715c7768f"
      },
      "source": [
        "# Sample of tokens \r\n",
        "\r\n",
        "print (take(5, tokeniser.token_to_index.items()))\r\n",
        "print (f\"least freq tokens freq: {tokeniser.min_token_freq}\") # use this to adjust num tokens"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[('<PAD>', 0), ('<UNK>', 1), ('39', 2), ('b', 3), ('gt', 4)]\n",
            "least freq tokens freq: 166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y1tmtwozS5O",
        "outputId": "d8c3d869-7c17-48de-ad3a-d6d21dd796ca"
      },
      "source": [
        "# Convert texts to sequences of indices \r\n",
        "\r\n",
        "X_train = tokeniser.texts_to_sequence(X_train)\r\n",
        "X_val = tokeniser.texts_to_sequence(X_val)\r\n",
        "X_test = tokeniser.texts_to_sequence(X_test)\r\n",
        "\r\n",
        "preprocessed_text = tokeniser.sequences_to_texts([X_train[0]])[0]\r\n",
        "print (\"Text to indices: \\n\"\r\n",
        "    f\" (preprocessed) -> {preprocessed_text}\\n\"\r\n",
        "    f\" (tokenised) -> {X_train[0]}\")"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text to indices: \n",
            " (preprocessed) -> china <UNK> north korea nuclear talks\n",
            " (tokenised) -> [ 16   1 285 142 114  24]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXswfqRo0GmE"
      },
      "source": [
        "# One-hot Encoding \r\n",
        "\r\n",
        "# - Creates a binary column fro each unique value of each feature. \r\n",
        "# -- All the values for the token will be 0 except the index of that specific token"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KG7EDYm513fS"
      },
      "source": [
        "def to_categorical(seq, num_classes):\r\n",
        "  \"\"\"One-hot encode a sequence of tokens.\"\"\"\r\n",
        "  one_hot = np.zeros((len(seq), num_classes))\r\n",
        "  for i, item in enumerate(seq):\r\n",
        "    one_hot[i, item] = 1.\r\n",
        "  return one_hot"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cuH7iXsj2Ww1",
        "outputId": "264e0d85-b07b-4386-c8ea-f12d6879ca8a"
      },
      "source": [
        "# One-hot encoding \r\n",
        "print (X_train[0])\r\n",
        "print (len(X_train[0]))\r\n",
        "cat = to_categorical(seq = X_train[0], num_classes = len(tokeniser))\r\n",
        "\r\n",
        "print (cat)\r\n",
        "print (cat.shape)"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 16   1 285 142 114  24]\n",
            "6\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "(6, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bkcutvt2rQP"
      },
      "source": [
        "# Convert tokens to one-hot\r\n",
        "\r\n",
        "vocab_size = len(tokeniser)\r\n",
        "X_train = [to_categorical(seq, num_classes = vocab_size) for seq in X_train]\r\n",
        "X_val = [to_categorical(seq, num_classes = vocab_size) for seq in X_val]\r\n",
        "X_test = [to_categorical(seq, num_classes = vocab_size) for seq in X_test]"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IfQQZ4P93Oy0"
      },
      "source": [
        "# Padding \r\n",
        "\r\n",
        "# - all the inputs have varying lengths, but each batch needs to e uniformly shaped\r\n",
        "# - we can use padding to make all the inputs in the batch the same length\r\n",
        "# - the padding index will be 0\r\n",
        "\r\n",
        "## ** one-hot encoding creates a batch of shape (N, max_seq_len, vocab_size) so we'll need to pad 3D sequences "
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFz7Go4m30W3"
      },
      "source": [
        "def pad_sequences(sequences, max_seq_len = 0):\r\n",
        "  \"\"\"Pad sequences to max length in sequence.\"\"\"\r\n",
        "  max_seq_len = max(max_seq_len, max(len(sequence) for sequence in sequences))\r\n",
        "  num_classes = sequences[0].shape[-1]\r\n",
        "  padded_sequences = np.zeros((len(sequences), max_seq_len, num_classes))\r\n",
        "  for i, sequence in enumerate(sequences):\r\n",
        "    padded_sequences[i][:len(sequence)] = sequence\r\n",
        "  return padded_sequences"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHFOCr1H4rE_",
        "outputId": "ab7a63a7-64d2-4162-a15d-3db2ace7992a"
      },
      "source": [
        "# 3D sequences \r\n",
        "\r\n",
        "print (X_train[0].shape, X_train[1].shape, X_train[2].shape)\r\n",
        "padded = pad_sequences(X_train[0:3])\r\n",
        "print (padded.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 500) (5, 500) (6, 500)\n",
            "(3, 6, 500)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDFPyGyJ5CAT"
      },
      "source": [
        "# Dataset\r\n",
        "# - here we need to create datasets and dataloaders to be able to efficiently create batches with the data splits \r\n",
        "\r\n",
        "FILTER_SIZE = 1 # unigram"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTMezleJ6U7q"
      },
      "source": [
        "class Dataset(torch.utils.data.Dataset):\r\n",
        "  def __init__(self, X, y, max_filter_size):\r\n",
        "    self.X = X\r\n",
        "    self.y = y\r\n",
        "    self.max_filter_size = max_filter_size\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.y)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<Dataset(N = {len(self)})>\"\r\n",
        "\r\n",
        "  def __getitem__(self, index):\r\n",
        "    X = self.X[index]\r\n",
        "    y = self.y[index]\r\n",
        "    return [X, y]\r\n",
        "\r\n",
        "  def collate_fn(self, batch):\r\n",
        "    \"\"\"Processing on batch.\"\"\"\r\n",
        "    # Get inputs\r\n",
        "    X = np.array(batch, dtype = object)[:, 0]\r\n",
        "    y = np.stack(np.array(batch, dtype = object)[:, 1], axis = 0)\r\n",
        "\r\n",
        "    # Pad sequences \r\n",
        "    X = pad_sequences(X, max_seq_len = self.max_filter_size)\r\n",
        "\r\n",
        "    # Cast\r\n",
        "    X = torch.FloatTensor(X.astype(np.int32))\r\n",
        "    y = torch.LongTensor(y.astype(np.int32))\r\n",
        "\r\n",
        "    return X, y\r\n",
        "\r\n",
        "  def create_dataloader(self, batch_size, shuffle = False, drop_last = False):\r\n",
        "    return torch.utils.data.DataLoader(\r\n",
        "        dataset = self, batch_size = batch_size, collate_fn = self.collate_fn, \r\n",
        "        shuffle = shuffle, drop_last = drop_last, pin_memory = True)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXoY27PZ8Q5u",
        "outputId": "82888948-1fa7-4189-ef1e-1405f77d15ac"
      },
      "source": [
        "# Create datasets for embedding \r\n",
        "\r\n",
        "train_dataset = Dataset(X = X_train, y = y_train, max_filter_size = FILTER_SIZE)\r\n",
        "val_dataset = Dataset(X = X_val, y = y_val, max_filter_size = FILTER_SIZE)\r\n",
        "test_dataset = Dataset(X = X_test, y = y_test, max_filter_size = FILTER_SIZE)\r\n",
        "print (\"Datasets: \\n\"\r\n",
        "    f\" Train dataset: {train_dataset.__str__()}\\n\"\r\n",
        "    f\" Val dataset: {val_dataset.__str__()}\\n\"\r\n",
        "    f\" Test dataset: {test_dataset.__str__()}\\n\"\r\n",
        "    \"Sample Point: \\n\"\r\n",
        "    f\" X: {test_dataset[0][0]}\\n\"\r\n",
        "    f\" y: {test_dataset[0][1]}\")"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets: \n",
            " Train dataset: <Dataset(N = 84000)>\n",
            " Val dataset: <Dataset(N = 18000)>\n",
            " Test dataset: <Dataset(N = 18000)>\n",
            "Sample Point: \n",
            " X: [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]\n",
            " [0. 1. 0. ... 0. 0. 0.]]\n",
            " y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "En480uM4-uS7",
        "outputId": "7fc61005-232f-438b-cebf-d981f2412049"
      },
      "source": [
        "# Create dataloaders \r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "train_dataloader = train_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "val_dataloader = val_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "test_dataloader = test_dataset.create_dataloader(batch_size = batch_size)\r\n",
        "batch_X, batch_y = next(iter(test_dataloader))\r\n",
        "print (\"Sample batch:\\n\"\r\n",
        "    f\" X: {list(batch_X.size())}\\n\"\r\n",
        "    f\" y: {list(batch_y.size())}\\n\"\r\n",
        "    \"Sample point:\\n\"\r\n",
        "    f\" X: {batch_X[0]}\\n\"\r\n",
        "    f\" y: {batch_y[0]}\")"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sample batch:\n",
            " X: [64, 14, 500]\n",
            " y: [64]\n",
            "Sample point:\n",
            " X: tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cpu')\n",
            " y: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W3T_oqa4DcoL"
      },
      "source": [
        "# CNN - Convolutional Neural Networks \r\n",
        "\r\n",
        "# - Here we will learn about CNNs by applying them on 1D text data\r\n",
        "# In the example below, we have a batch of N samples where wach sample has 8 characters and each char represented by an array of 10 values (vocab size = 10)\r\n",
        "# - this gives our inputs the size (N, 8, 10)\r\n",
        "\r\n",
        "# -- with PyTorch, when dealing with convs, the inputs X need to have the channels as the second dimension, so our inputs will be (N,10,8)\r\n",
        "\r\n",
        "import math\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfdX2dWkG4KD",
        "outputId": "a37f8ee2-ad29-446f-b3a7-53c8b0a90172"
      },
      "source": [
        "# Assume all our inputs are padded to have the same words\r\n",
        "\r\n",
        "batch_size = 64\r\n",
        "max_seq_len = 8 # words per input\r\n",
        "vocab_size = 10 # one hot size\r\n",
        "x = torch.randn(batch_size, max_seq_len, vocab_size)\r\n",
        "print (f\" X:{x.shape}\")\r\n",
        "x = x.transpose(1, 2)\r\n",
        "print (f\" X:{x.shape}\")"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " X:torch.Size([64, 8, 10])\n",
            " X:torch.Size([64, 10, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flM_mMvwH80y"
      },
      "source": [
        "# At the core of CNNs are filters, also known as weights, kernels etc), which convolve (slide) across our input to extract relevant features. \r\n",
        "# the filters are initialised randomly but learn to act as feature extractors via parameter sharing.\r\n",
        "\r\n",
        "# We will use a conv1d layer to process our inouts "
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dGCgRgglLTMD",
        "outputId": "2e8db75d-08f2-4487-b647-2e35a433c2d6"
      },
      "source": [
        "# Convolutional filters (Valid padding)\r\n",
        "\r\n",
        "vocab_size = 10 # one-hot size\r\n",
        "num_filters = 50 # num of filters \r\n",
        "filter_size = 3 # filters are 3 X 3 \r\n",
        "stride = 1\r\n",
        "padding = 0 # valid padding (no padding)\r\n",
        "conv1 = nn.Conv1d(in_channels = vocab_size, out_channels = num_filters, \r\n",
        "                  kernel_size = filter_size, stride = stride, \r\n",
        "                  padding = padding, padding_mode = \"zeros\")\r\n",
        "print (\"conv: {}\".format(conv1.weight.shape))"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBK_HURrMKJl",
        "outputId": "7dfc7a75-415f-4078-97e2-ee3c16a6a4fa"
      },
      "source": [
        "# Forward pass\r\n",
        "z = conv1(x)\r\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ3NIvVtMTjV"
      },
      "source": [
        "# Now, we'll add padding so that the convolutional outputs are the same shape as our inputs. \r\n",
        "# - we want our output to have the same width as our input. "
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVMB5lgXNPVT",
        "outputId": "c53fcf9a-8649-41b2-f9de-15c3f49e22e2"
      },
      "source": [
        "# Convolutional filters (Same padding)\r\n",
        "\r\n",
        "vocab_size = 10 # one-hot size\r\n",
        "num_filters = 50 # num filters \r\n",
        "filter_size = 3 # filters are 3 X 3\r\n",
        "stride = 1\r\n",
        "conv = nn.Conv1d(in_channels = vocab_size, out_channels = num_filters, \r\n",
        "                 kernel_size = filter_size, stride = stride)\r\n",
        "print (\"conv: {}\".format(conv.weight.shape))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "conv: torch.Size([50, 10, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqdlRQTuN4LV",
        "outputId": "82987aaf-ff28-4042-f37a-918142a112c4"
      },
      "source": [
        "# Same padding \r\n",
        "\r\n",
        "padding_left = int((conv.stride[0] * (max_seq_len-1) - max_seq_len + filter_size) / 2)\r\n",
        "padding_right = int(math.ceil((conv.stride[0] * (max_seq_len - 1) - max_seq_len + filter_size) / 2))\r\n",
        "print (f\"padding: {(padding_left, padding_right)}\")"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "padding: (1, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEGUkVCgdMmT",
        "outputId": "726f17a6-e115-40d8-e39c-1a5c3f7e6424"
      },
      "source": [
        "# Forward pass \r\n",
        "\r\n",
        "z = conv(F.pad(x, (padding_left, padding_right)))\r\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 8])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UOMcR8txdk-g",
        "outputId": "f39e9b4b-355a-4d13-abeb-6f5ac7124966"
      },
      "source": [
        "# Pooling \r\n",
        "\r\n",
        "# - the result of the convolving filters on an input is a feature map. Due to the nature of convolution and overlaps,our feature map will have lots of redundant information.\r\n",
        "# - Pooling is a way to summarise a high-dimensional feature map into a lower dimensional one for simplified downstream computation. \r\n",
        "# -- the pooling operation can be the max value, average etc\r\n",
        "\r\n",
        "# Max pooling \r\n",
        "\r\n",
        "pool_output = F.max_pool1d(z, z.size(2))\r\n",
        "print (\"Size: {}\".format(pool_output.shape))"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size: torch.Size([64, 50, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZZSujn3Efqiv"
      },
      "source": [
        "# Batch normalisation \r\n",
        "\r\n",
        "# - this is an operation that will standardise the activations from the previous layer \r\n",
        "# recall that we've previously standardised our inputs so that the model can optimise quickly with larger learning learning rates\r\n",
        "# - here we will use the same concept  but we will continue to maintain standardised values throughout the forward pass to further aid optimisation"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dv8TyhVdkR7N",
        "outputId": "60dc6469-9298-4131-fa39-e08befe4bdc5"
      },
      "source": [
        "batch_norm = nn.BatchNorm1d(num_features = num_filters)\r\n",
        "z = batch_norm(conv(x)) # applied to activations (after conv layer & before pooling)\r\n",
        "print (f\"z: {z.shape}\")"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "z: torch.Size([64, 50, 6])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8bwjkmvkp8N",
        "outputId": "5957626a-e619-4fc6-ff31-1a37bf31bef9"
      },
      "source": [
        "# Mean and std before batchnorm\r\n",
        "print (f\"mean: {torch.mean(conv1(x)):.2f}, std: {torch.std(conv(x)):.2f}\")"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: 0.01, std: 0.57\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVnRsWN4lCoa",
        "outputId": "1a36fb60-06bb-4bc7-f444-2af4e3046a38"
      },
      "source": [
        "# Mean and std after batchnorm\r\n",
        "print (f\"mean: {torch.mean(z):.2f}, std: {torch.std(z):.2f}\")"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean: 0.00, std: 1.00\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dRV-VYzlSMQ"
      },
      "source": [
        "# Modelling \r\n",
        "\r\n",
        "# First, tokenise the inputs (batch_size, max_seq_len)\r\n",
        "# Then, one-hot encode the tokenised inputs(batch_size, max_seq_len, vocab_size)\r\n",
        "# After, apply, conv filters (filter_size, vocab_size, num_filters) then, batch norm\r\n",
        "# Then, apply 1D global max pooling which will extract the most rlevant information from th feature maps for making the decision\r\n",
        "# After, feed the pool outputs to a fully connected layer with dropout\r\n",
        "# Last, we use one more fully connected layer with Softmax to derive class probabilities"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d23oWYx7pwRv"
      },
      "source": [
        "NUM_FILTERS = 50\r\n",
        "HIDDEN_DIM = 100\r\n",
        "DROPOUT_P = 0.1"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im1D9qFrs3Qm"
      },
      "source": [
        "class CNN(nn.Module):\r\n",
        "  def __init__(self, vocab_size, num_filters, filter_size, hidden_dim, dropout_p, num_classes):\r\n",
        "    super(CNN, self).__init__()\r\n",
        "\r\n",
        "    # Convolutional filters \r\n",
        "    self.filter_size = filter_size\r\n",
        "    self.conv = nn.Conv1d(\r\n",
        "        in_channels = vocab_size, out_channels = num_filters, \r\n",
        "        kernel_size = filter_size, stride = 1, padding = 0, padding_mode = \"zeros\")\r\n",
        "    self.batch_norm = nn.BatchNorm1d(num_features = num_filters)\r\n",
        "\r\n",
        "    # Fully Connected layers\r\n",
        "    self.fc1 = nn.Linear(num_filters, hidden_dim)\r\n",
        "    self.dropout_p = nn.Dropout(dropout_p)\r\n",
        "    self.fc2 = nn.Linear(hidden_dim, num_classes)\r\n",
        "\r\n",
        "  def forward(self, inputs, channel_first = False, apply_softmax = False):\r\n",
        "    # Rearrange input so num_channels is in dim 1 (N, C, L)\r\n",
        "    x_in, = inputs\r\n",
        "    if not channel_first:\r\n",
        "      x_in = x_in.transpose(1, 2)\r\n",
        "\r\n",
        "    # Padding for SAME padding \r\n",
        "    max_seq_len = x_in.shape[2]\r\n",
        "    padding_left = int((self.conv.stride[0] * (max_seq_len -1) - max_seq_len + self.filter_size) / 2)\r\n",
        "    padding_right = int(math.ceil((self.conv.stride[0] * (max_seq_len) - max_seq_len + self.filter_size) / 2))\r\n",
        "\r\n",
        "    # Conv outputs \r\n",
        "    z = self.conv(F.pad(x_in, (padding_left, padding_right))) \r\n",
        "    z = F.max_pool1d(z, z.size(2)).squeeze(2)\r\n",
        "\r\n",
        "    # Fully connected layer \r\n",
        "    z = self.fc1(z)\r\n",
        "    z = self.dropout_p(z)\r\n",
        "    y_pred = self.fc2(z)\r\n",
        "\r\n",
        "    if apply_softmax:\r\n",
        "      y_pred = F.softmax(y_pred, dim = 1)\r\n",
        "    return y_pred"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpyB3YRLwYHa",
        "outputId": "544e162a-c4e6-427a-fc3f-b3f026108e4f"
      },
      "source": [
        "# Initialising the model \r\n",
        "\r\n",
        "model = CNN(vocab_size = VOCAB_SIZE, num_filters = NUM_FILTERS, filter_size = FILTER_SIZE,\r\n",
        "            hidden_dim = HIDDEN_DIM,dropout_p = DROPOUT_P, num_classes = NUM_CLASSES )\r\n",
        "model = model.to(device) # set device\r\n",
        "print (model.named_parameters)"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<bound method Module.named_parameters of CNN(\n",
            "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
            "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
            "  (dropout_p): Dropout(p=0.1, inplace=False)\n",
            "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
            ")>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8chLlkLP45Wr"
      },
      "source": [
        "# Training \r\n",
        "\r\n",
        "from torch.optim import Adam"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z40Gq1Ff5FNR"
      },
      "source": [
        "LEARNING_RATE = 1e-3\r\n",
        "PATIENCE = 5\r\n",
        "NUM_EPOCHS = 10"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7w3jMf615MlO"
      },
      "source": [
        "class Trainer(object):\r\n",
        "  def __init__(self, model, device, loss = None, optimiser = None, scheduler = None):\r\n",
        "    \r\n",
        "    # Set params \r\n",
        "    self.model = model \r\n",
        "    self.device = device \r\n",
        "    self.loss = loss\r\n",
        "    self.optimiser = optimiser\r\n",
        "    self.scheduler = scheduler\r\n",
        "\r\n",
        "  def train_step(self, dataloader):\r\n",
        "    \"\"\"Train step.\"\"\"\r\n",
        "    # Set model to train mode \r\n",
        "    self.model.train()\r\n",
        "    loss = 0.0\r\n",
        "\r\n",
        "    # Iterate over train batches\r\n",
        "    for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "      # Step\r\n",
        "      batch = [item.to(self.device) for item in batch] # Set device \r\n",
        "      inputs, targets = batch[:-1], batch[-1]\r\n",
        "      self.optimiser.zero_grad() # Reset gradients \r\n",
        "      z = self.model(inputs) # Forward pass\r\n",
        "      J = self.loss(z, targets) # Define loss\r\n",
        "      J.backward() # Backward pass \r\n",
        "      self.optimiser.step() # Update weights\r\n",
        "\r\n",
        "      # Cumulative metrics \r\n",
        "      loss += (J.detach().item() - loss) / (i + 1)\r\n",
        "\r\n",
        "    return loss\r\n",
        "  \r\n",
        "  def eval_step(self, dataloader):\r\n",
        "    \"\"\"Validation of test step.\"\"\"\r\n",
        "    # Set model to eval mode\r\n",
        "    self.model.eval()\r\n",
        "    loss = 0.0\r\n",
        "    y_trues, y_probs = [], []\r\n",
        "\r\n",
        "    # Iterate over the val batches \r\n",
        "    with torch.no_grad():\r\n",
        "      for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "        # Step\r\n",
        "        batch = [item.to(self.device) for item in batch] # Set device\r\n",
        "        inputs, y_true = batch[:-1], batch[-1]\r\n",
        "        z = self.model(inputs) # Forward pass\r\n",
        "        J = self.loss(z, y_true).item()\r\n",
        "\r\n",
        "        # Cumulative Metrics \r\n",
        "        loss += (J - loss) / (i + 1)\r\n",
        "\r\n",
        "        # Store outputs \r\n",
        "        y_prob = torch.sigmoid(z).cpu().numpy()\r\n",
        "        y_probs.extend(y_prob)\r\n",
        "        y_trues.extend(y_true.cpu().numpy())\r\n",
        "    \r\n",
        "    return loss, np.vstack(y_trues), np.vstack(y_probs)\r\n",
        "\r\n",
        "  def predict_step(self, dataloader):\r\n",
        "    \"\"\"Prediction step.\"\"\"\r\n",
        "    # Set model to eval mode\r\n",
        "    self.model.eval()\r\n",
        "    y_probs = []\r\n",
        "\r\n",
        "    # Iterate over the val batches\r\n",
        "    with torch.no_grad():\r\n",
        "      for i, batch in enumerate(dataloader):\r\n",
        "\r\n",
        "        # Forward pass w/ inputs \r\n",
        "        inputs, targets = batch[:-1], batch[-1]\r\n",
        "        y_prob = self.model(inputs, apply_softmax = True)\r\n",
        "\r\n",
        "        # Store outputs\r\n",
        "        y_probs.extend(y_prob)\r\n",
        "\r\n",
        "    return np.vstack(y_probs)\r\n",
        "\r\n",
        "  def train(self, num_epochs, patience, train_dataloader, val_dataloader):\r\n",
        "    best_val_loss = np.inf\r\n",
        "    for epoch in range(num_epochs):\r\n",
        "\r\n",
        "      # Steps\r\n",
        "      train_loss = self.train_step(dataloader = train_dataloader)\r\n",
        "      val_loss, _, _ = self.eval_step(dataloader = val_dataloader)\r\n",
        "\r\n",
        "      # Early stopping\r\n",
        "      if val_loss < best_val_loss:\r\n",
        "        best_val_loss = val_loss\r\n",
        "        best_model = self.model\r\n",
        "        _patience = patience # Reset patience \r\n",
        "      else:\r\n",
        "        _patience -= 1\r\n",
        "      if not _patience: # 0\r\n",
        "        print (\"Stopping early!\")\r\n",
        "        break\r\n",
        "\r\n",
        "      # Logging\r\n",
        "      print (\r\n",
        "          f\"Epoch: {epoch +1} | \"\r\n",
        "          f\"train_loss: {train_loss:.5f}, \"\r\n",
        "          f\"val_loss: {val_loss:.5f}, \"\r\n",
        "          f\"lr: {self.optimiser.param_groups[0]['lr']:.2E}, \"\r\n",
        "          f\"_patience: {_patience}\"\r\n",
        "      )\r\n",
        "    return best_model\r\n"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6DrujMEBIrt"
      },
      "source": [
        "# Define loss\r\n",
        "\r\n",
        "class_weights_tensor = torch.Tensor(list(class_weights.values())).to(device)\r\n",
        "loss = nn.CrossEntropyLoss(weight = class_weights_tensor)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaOx3-5sBrkM"
      },
      "source": [
        "# Define optimiser and scheduler\r\n",
        "\r\n",
        "optimiser = Adam(model.parameters(), lr = LEARNING_RATE)\r\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\r\n",
        "    optimiser, mode = 'min', factor = 0.1, patience = 3)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sdHfoM7eCEdY"
      },
      "source": [
        "# Trainer module\r\n",
        "\r\n",
        "trainer = Trainer(\r\n",
        "    model = model, device = device, loss = loss, \r\n",
        "    optimiser = optimiser, scheduler = scheduler)"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4mJ6Mm5EyPd",
        "outputId": "fc0354db-0f01-4177-8dd1-37048971a2c2"
      },
      "source": [
        "# Train\r\n",
        "best_model = trainer.train(\r\n",
        "    NUM_EPOCHS, PATIENCE, train_dataloader, val_dataloader)"
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1 | train_loss: 0.87454, val_loss: 0.79113, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 2 | train_loss: 0.78471, val_loss: 0.78694, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 3 | train_loss: 0.77998, val_loss: 0.78519, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 4 | train_loss: 0.77678, val_loss: 0.78441, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 5 | train_loss: 0.77483, val_loss: 0.78339, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 6 | train_loss: 0.77326, val_loss: 0.78268, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 7 | train_loss: 0.77227, val_loss: 0.78248, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 8 | train_loss: 0.77135, val_loss: 0.78251, lr: 1.00E-03, _patience: 4\n",
            "Epoch: 9 | train_loss: 0.77042, val_loss: 0.78203, lr: 1.00E-03, _patience: 5\n",
            "Epoch: 10 | train_loss: 0.76958, val_loss: 0.78201, lr: 1.00E-03, _patience: 5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0O5TxEf2GIhX"
      },
      "source": [
        "# Evaluation \r\n",
        "\r\n",
        "import json\r\n",
        "from pathlib import Path\r\n",
        "from sklearn.metrics import precision_recall_fscore_support"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj7zc1tEKVeF"
      },
      "source": [
        "def get_performance(y_true, y_pred, classes):\r\n",
        "  \"\"\"Per-class performance metrics.\"\"\"\r\n",
        "  # Get metrics \r\n",
        "  performance = {\"overall\": {}, \"class\": {}}\r\n",
        "  metrics = precision_recall_fscore_support(y_true, y_pred)\r\n",
        "\r\n",
        "  # Overall performance \r\n",
        "  performance[\"overall\"][\"precision\"] = np.mean(metrics[0])\r\n",
        "  performance[\"overall\"][\"recall\"] = np.mean(metrics[1])\r\n",
        "  performance[\"overall\"][\"f1\"] = np.mean(metrics[2])\r\n",
        "  performance[\"overall\"][\"num_samples\"] = np.float64(np.sum(metrics[3]))\r\n",
        "\r\n",
        "  # Per class performance\r\n",
        "  for i in range(len(classes)):\r\n",
        "    performance[\"class\"][classes[i]] = {\r\n",
        "        \"precision\": metrics[0][i], \r\n",
        "        \"recall\": metrics[1][i], \r\n",
        "        \"f1\": metrics[2][i], \r\n",
        "        \"num_samples\": np.float64(metrics[3][i])\r\n",
        "    }\r\n",
        "  return performance"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3ZmkT-ANPGj"
      },
      "source": [
        "# get predictions \r\n",
        "\r\n",
        "test_loss, y_true, y_prob = trainer.eval_step(dataloader = test_dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis = 1)"
      ],
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvhiJNiQNcTF",
        "outputId": "cbe1dae8-75c1-426f-a790-ae13762ae057"
      },
      "source": [
        "# Determine performance \r\n",
        "performance = get_performance(\r\n",
        "    y_true = y_test, y_pred = y_pred, classes = label_encoder.classes)\r\n",
        "print (json.dumps(performance[\"overall\"], indent = 2))"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"precision\": 0.7115579309819231,\n",
            "  \"recall\": 0.6917222222222221,\n",
            "  \"f1\": 0.6911547384674819,\n",
            "  \"num_samples\": 18000.0\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q-jC-2aNyxP"
      },
      "source": [
        "# Save artifacts \r\n",
        "\r\n",
        "dir = Path(\"cnn\")\r\n",
        "dir.mkdir(parents = True, exist_ok = True)\r\n",
        "label_encoder.save(fp = Path(dir, \"label_encoder.json\"))\r\n",
        "tokeniser.save(fp = Path(dir, \"tokeniser.json\"))\r\n",
        "torch.save(best_model.state_dict(), Path(dir, \"model.pt\"))\r\n",
        "with open(Path(dir, \"performance.json\"), \"w\") as fp:\r\n",
        "  json.dump(performance, indent = 2, sort_keys = False, fp = fp)"
      ],
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S6waZLEpO18N"
      },
      "source": [
        "# Inference \r\n",
        "def get_probability_distribution(y_prob, classes):\r\n",
        "  \"\"\"Create a dict of class probabilities from an array.\"\"\"\r\n",
        "  results = {}\r\n",
        "  for i, class_ in enumerate(classes):\r\n",
        "    results[class_] = np.float64(y_prob[i])\r\n",
        "  sorted_results = {k: v for k, v in sorted(\r\n",
        "      results.items(), key = lambda item: item[1], reverse = True)}\r\n",
        "  return sorted_results\r\n"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Vi-1OmuQy34",
        "outputId": "8c1e7cda-9e70-4008-893c-4ad08d7eb376"
      },
      "source": [
        "# Load artifacts\r\n",
        "device = torch.device(\"cpu\")\r\n",
        "label_encoder = LabelEncoder.load(fp=Path(dir, 'label_encoder.json'))\r\n",
        "tokeniser = Tokeniser.load(fp=Path(dir, 'tokeniser.json'))\r\n",
        "model = CNN(\r\n",
        "    vocab_size=VOCAB_SIZE, num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)\r\n",
        "model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\r\n",
        "model.to(device)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout_p): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6ML4nTkSnVq"
      },
      "source": [
        "# Initialise trainer \r\n",
        "\r\n",
        "trainer = Trainer(model = model, device = device)"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOsiO8GOWKWa",
        "outputId": "12537b02-65eb-4c95-e0e2-0e058a6aa9bf"
      },
      "source": [
        "# Dataloader \r\n",
        "\r\n",
        "text = \"What a day for the new york stock market to go burst!\"\r\n",
        "sequences = tokeniser.texts_to_sequence([preprocess(text)])\r\n",
        "print (tokeniser.sequences_to_texts(sequences))\r\n",
        "X = [to_categorical(seq, num_classes = len(tokeniser)) for seq in sequences]\r\n",
        "y_filler = label_encoder.encode([label_encoder.classes[0]] * len(X))\r\n",
        "dataset = Dataset(X = X, y = y_filler, max_filter_size = FILTER_SIZE)\r\n",
        "dataloader = dataset.create_dataloader(batch_size = batch_size)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['day new <UNK> stock market go <UNK>']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf7AubVYXGzu",
        "outputId": "8473eb64-33aa-44aa-9a3b-5b2f9cc1b4bb"
      },
      "source": [
        "# Inference\r\n",
        "\r\n",
        "y_prob = trainer.predict_step(dataloader)\r\n",
        "y_pred = np.argmax(y_prob, axis = 1)\r\n",
        "label_encoder.decode(y_pred)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Business']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkpHPBDPXp9Z",
        "outputId": "cd6128e0-2e12-45cf-fab6-3ddc14bb664a"
      },
      "source": [
        "# Class distributions\r\n",
        "\r\n",
        "prob_dist = get_probability_distribution(y_prob = y_prob[0], classes = label_encoder.classes)\r\n",
        "print (json.dumps(prob_dist, indent = 2))"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"Business\": 0.8190300464630127,\n",
            "  \"Sci/Tech\": 0.16043992340564728,\n",
            "  \"World\": 0.014267615973949432,\n",
            "  \"Sports\": 0.006262409966439009\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyaVQzkAX-vf"
      },
      "source": [
        "# Interpretability \r\n",
        "\r\n",
        "# - We went through all the trouble of padding our inputs before convolution to result is outputs of the same shape as our inputs so we can try to get some interpretability. \r\n",
        "# - Since every token is mapped to a convolutional output on whcih we apply max pooling,\r\n",
        "# we can see which token's output was most influential towards the prediction. We first need to get the conv outputs from our model:\r\n",
        "\r\n",
        "import collections\r\n",
        "import seaborn as sns"
      ],
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Lp6Go81ZePF"
      },
      "source": [
        "class InterpretableCNN(nn.Module):\r\n",
        "    def __init__(self, vocab_size, num_filters, filter_size,\r\n",
        "                 hidden_dim, dropout_p, num_classes):\r\n",
        "        super(InterpretableCNN, self).__init__()\r\n",
        "\r\n",
        "        # Convolutional filters\r\n",
        "        self.filter_size = filter_size\r\n",
        "        self.conv = nn.Conv1d(\r\n",
        "            in_channels=vocab_size, out_channels=num_filters,\r\n",
        "            kernel_size=filter_size, stride=1, padding=0, padding_mode='zeros')\r\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=num_filters)\r\n",
        "\r\n",
        "        # FC layers\r\n",
        "        self.fc1 = nn.Linear(num_filters, hidden_dim)\r\n",
        "        self.dropout = nn.Dropout(dropout_p)\r\n",
        "        self.fc2 = nn.Linear(hidden_dim, num_classes)\r\n",
        "\r\n",
        "    def forward(self, inputs, channel_first=False, apply_softmax=False):\r\n",
        "\r\n",
        "        # Rearrange input so num_channels is in dim 1 (N, C, L)\r\n",
        "        x_in, = inputs\r\n",
        "        if not channel_first:\r\n",
        "            x_in = x_in.transpose(1, 2)\r\n",
        "\r\n",
        "        # Padding for `SAME` padding\r\n",
        "        max_seq_len = x_in.shape[2]\r\n",
        "        padding_left = int((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2)\r\n",
        "        padding_right = int(math.ceil((self.conv.stride[0]*(max_seq_len-1) - max_seq_len + self.filter_size)/2))\r\n",
        "\r\n",
        "        # Conv outputs\r\n",
        "        z = self.conv(F.pad(x_in, (padding_left, padding_right)))\r\n",
        "\r\n",
        "        return z"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFy6XRL7ZpH3"
      },
      "source": [
        "# Initialize\r\n",
        "interpretable_model = InterpretableCNN(\r\n",
        "    vocab_size=len(tokeniser), num_filters=NUM_FILTERS, filter_size=FILTER_SIZE,\r\n",
        "    hidden_dim=HIDDEN_DIM, dropout_p=DROPOUT_P, num_classes=NUM_CLASSES)"
      ],
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teQX1bcTZtgf",
        "outputId": "0ce2d543-58ec-45cd-f080-7f29971d0de5"
      },
      "source": [
        "# Load weights (same architecture)\r\n",
        "interpretable_model.load_state_dict(torch.load(Path(dir, 'model.pt'), map_location=device))\r\n",
        "interpretable_model.to(device)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InterpretableCNN(\n",
              "  (conv): Conv1d(500, 50, kernel_size=(1,), stride=(1,))\n",
              "  (batch_norm): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (fc1): Linear(in_features=50, out_features=100, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (fc2): Linear(in_features=100, out_features=4, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XWKX_j5rZz-K"
      },
      "source": [
        "# Initialize trainer\r\n",
        "interpretable_trainer = Trainer(model=interpretable_model, device=device)"
      ],
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_cH5JA4Z4y6",
        "outputId": "d9597628-cc52-4624-9585-fcb0be13a25e"
      },
      "source": [
        "# Get conv outputs\r\n",
        "conv_outputs = interpretable_trainer.predict_step(dataloader)\r\n",
        "print (conv_outputs.shape) # (num_filters, max_seq_len)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(50, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "id": "uH5RHPsvZ8I5",
        "outputId": "24e73d33-4f7f-4ff7-e0da-5558ded598c6"
      },
      "source": [
        "# Visualize a bi-gram filter's outputs\r\n",
        "tokens = tokeniser.sequences_to_texts(sequences)[0].split(' ')\r\n",
        "sns.heatmap(conv_outputs, xticklabels=tokens)"
      ],
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fe33cbaa470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUO6yureZ-eM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}