{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Back to Basics: CNNs",
      "provenance": [],
      "authorship_tag": "ABX9TyN/ZYU26wL0PIApmeIj+6N8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Otobi1/Back-to-Basics-A-Refresher-/blob/master/Back_to_Basics_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSEYD28OfPkb"
      },
      "source": [
        "## Set up \r\n",
        "\r\n",
        "import numpy as np \r\n",
        "import pandas as pd\r\n",
        "import random \r\n",
        "import torch \r\n",
        "import torch.nn as nn"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "759r6mk1ZUM_"
      },
      "source": [
        "SEED = 1234"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1MqZJHqAZV1x"
      },
      "source": [
        "def set_seeds(seed = 1234):\r\n",
        "  \"\"\"Set seed for reproducibility.\"\"\"\r\n",
        "  np.random.seed(seed)\r\n",
        "  random.seed(seed)\r\n",
        "  torch.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed(seed)\r\n",
        "  torch.cuda.manual_seed_all(seed) # multi GPU"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PP0JoHAEZ2XM"
      },
      "source": [
        "# Set seed for reproducibility \r\n",
        "\r\n",
        "set_seeds(seed=SEED)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWPpxlKIawys",
        "outputId": "d0d8e982-67a7-490e-d8b4-8cc28160014e"
      },
      "source": [
        "# Set device \r\n",
        "\r\n",
        "cuda = True\r\n",
        "device = torch.device(\"cuda\" if (\r\n",
        "    torch.cuda.is_available() and cuda) else \"cpu\")\r\n",
        "torch.set_default_tensor_type(\"torch.FloatTensor\")\r\n",
        "if device.type == \"cuda\":\r\n",
        "  torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\r\n",
        "print (device)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        },
        "id": "hNTtW2TjbX90",
        "outputId": "ec780beb-1197-4a79-9335-62491f05a905"
      },
      "source": [
        "# Load data \r\n",
        "# - corpus of news article from http://groups.di.unipi.it/~gulli/AG_corpus_of_news_articles.html \r\n",
        "\r\n",
        "url = \"https://raw.githubusercontent.com/GokuMohandas/madewithml/main/datasets/news.csv\"\r\n",
        "df = pd.read_csv(url, header = 0) # load\r\n",
        "df = df.sample(frac = 1).reset_index(drop = True) # shuffle\r\n",
        "df.head()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sharon Accepts Plan to Reduce Gaza Army Operat...</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Internet Key Battleground in Wildlife Crime Fight</td>\n",
              "      <td>Sci/Tech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>July Durable Good Orders Rise 1.7 Percent</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Growing Signs of a Slowing on Wall Street</td>\n",
              "      <td>Business</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The New Faces of Reality TV</td>\n",
              "      <td>World</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  category\n",
              "0  Sharon Accepts Plan to Reduce Gaza Army Operat...     World\n",
              "1  Internet Key Battleground in Wildlife Crime Fight  Sci/Tech\n",
              "2          July Durable Good Orders Rise 1.7 Percent  Business\n",
              "3          Growing Signs of a Slowing on Wall Street  Business\n",
              "4                        The New Faces of Reality TV     World"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NlO6lmtb5rN"
      },
      "source": [
        "# Preprocessing \r\n",
        "# - to clean up the data, convert to lower text, remove filler words and filter using regex.\r\n",
        "\r\n",
        "import nltk\r\n",
        "from nltk.corpus import stopwords\r\n",
        "from nltk.stem import PorterStemmer\r\n",
        "import re"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDTD_WxOcgyF",
        "outputId": "e43cddc5-b76d-41bf-82d2-2c5bbc344aea"
      },
      "source": [
        "nltk.download(\"stopwords\")\r\n",
        "STOPWORDS = stopwords.words(\"english\")\r\n",
        "print (STOPWORDS[:5])\r\n",
        "porter = PorterStemmer()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "['i', 'me', 'my', 'myself', 'we']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0oH6OeZdQld"
      },
      "source": [
        "def preprocess(text, stopwords = STOPWORDS):\r\n",
        "  \"\"\"Conditional preprocessing on our text unique to the task.\"\"\"\r\n",
        "  # Lower \r\n",
        "  text = text.lower()\r\n",
        "\r\n",
        "  # Remove stopwords\r\n",
        "  pattern = re.compile(r\"\\b(\" + r\"|\".join(stopwords) + r\")\\b\\s*\")\r\n",
        "  text = pattern.sub(\" \", text)\r\n",
        "\r\n",
        "  # Remove words in parenthesis\r\n",
        "  text = re.sub(r\"\\([^)]*\\)\", \" \", text)\r\n",
        "\r\n",
        "  # Spacing and filters \r\n",
        "  text = re.sub(r\"([-;;.,!?<=>])\", r\" \\1 \", text)\r\n",
        "  text = re.sub('[^A-Za-z0-9]+', ' ', text) # remove non alphanumeric characters\r\n",
        "  text = re.sub(' +', ' ', text) # remove multiple spaces \r\n",
        "  text = text.strip()\r\n",
        "\r\n",
        "  return text"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "K-DBYnbtgJXf",
        "outputId": "3bd94016-195c-416f-cdc2-d8c9747fad0f"
      },
      "source": [
        "# Sample \r\n",
        "\r\n",
        "text = \"Great week for the NYSE\"\r\n",
        "preprocess(text = text)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'great week nyse'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbVH3XrNgmJk",
        "outputId": "929a1a1f-da8e-4eb2-cf72-68fc003c42ba"
      },
      "source": [
        "# Apply to dataframe\r\n",
        "\r\n",
        "preprocessed_df = df.copy()\r\n",
        "preprocessed_df.title = preprocessed_df.title.apply(preprocess)\r\n",
        "print (f\"{df.title.values[0]}\\n\\n{preprocessed_df.title.values[0]}\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sharon Accepts Plan to Reduce Gaza Army Operation, Haaretz Says\n",
            "\n",
            "sharon accepts plan reduce gaza army operation haaretz says\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TLGqCnLhMJL"
      },
      "source": [
        "# if you have preprocessing steps like standardisation, that are calculated, you need to separate the training an dtest set first before applying those operations. \r\n",
        "# this is because we cannot apply any knowledge gained from the test set accidentally (data leak during preprocessing/training). \r\n",
        "# - for global preprocessing steps like the functin above, where we arent learning anything from the data itself, we can perform them before splitting the data."
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvGalMXshdP5"
      },
      "source": [
        "# Split the data \r\n",
        "\r\n",
        "import collections\r\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K2_5ayPKh7ak"
      },
      "source": [
        "TRAIN_SIZE = 0.7\r\n",
        "VAL_SIZE = 0.15\r\n",
        "TEST_SIZE = 0.15"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToTVRdVRiu6m"
      },
      "source": [
        "def train_val_test_split(X, y, train_size):\r\n",
        "  \"\"\"Split dataset into data split.\"\"\"\r\n",
        "  X_train, X_, y_train, y_ = train_test_split(X, y, train_size = TRAIN_SIZE, stratify = y)\r\n",
        "  X_val, X_test, y_val, y_test = train_test_split(X_, y_, train_size = 0.5, stratify = y_)\r\n",
        "  return X_train, X_val, X_test, y_train, y_val, y_test"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4dHEIRQjZoX"
      },
      "source": [
        "# Data\r\n",
        "X = preprocessed_df[\"title\"].values \r\n",
        "y = preprocessed_df[\"category\"].values"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJxEUiLbjh4V",
        "outputId": "1992dbb6-3ac0-40f1-c492-b458ea3b6b99"
      },
      "source": [
        "# Create data splits\r\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\r\n",
        "    X = X, y = y, train_size = TRAIN_SIZE)\r\n",
        "\r\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\r\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\r\n",
        "print (f\"X_train: {X_test.shape}, y_test: {y_test.shape}\")\r\n",
        "print (f\"Sample point: {X_train[0]} -> {y_train[0]}\")\r\n"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (84000,), y_train: (84000,)\n",
            "X_val: (18000,), y_val: (18000,)\n",
            "X_train: (18000,), y_test: (18000,)\n",
            "Sample point: china battles north korea nuclear talks -> World\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtvU0BHUkSEr"
      },
      "source": [
        "# Label Encoding \r\n",
        "# to encode the text labels into unique indices\r\n",
        "\r\n",
        "import itertools"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2cewudKkgVY"
      },
      "source": [
        "class LabelEncoder(object):\r\n",
        "  \"\"\"Label encoder for tag labels.\"\"\"\r\n",
        "  def __init__(self, class_to_index = {}):\r\n",
        "    self.class_to_index = class_to_index\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return len(self.class_to_index)\r\n",
        "\r\n",
        "  def __str__(self):\r\n",
        "    return f\"<LabelEncoder(num_classes = {len(self)})>\"\r\n",
        "  \r\n",
        "  def fit(self, y):\r\n",
        "    classes = np.unique(y_train)\r\n",
        "    for i, class_ in enumerate(classes):\r\n",
        "      self.class_to_index[class_] = i\r\n",
        "    self.index_to_class = {v: k for k, v in self.class_to_index.items()}\r\n",
        "    self.classes = list(self.class_to_index.keys())\r\n",
        "    return self\r\n",
        "\r\n",
        "  def encode(self, y):\r\n",
        "    encoded = np.zeros((len(y)), dtype = int)\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      encoded[i] = self.class_to_index[item]\r\n",
        "    return encoded\r\n",
        "\r\n",
        "  def decode(self, y):\r\n",
        "    classes = []\r\n",
        "    for i, item in enumerate(y):\r\n",
        "      classes.append(self.index_to_class[item])\r\n",
        "    return classes\r\n",
        "\r\n",
        "  def save(self, fp):\r\n",
        "    with open(fp, \"w\") as fp:\r\n",
        "      contents = {\"class_to_index\": self.class_to_index}\r\n",
        "      json.dump(contents, fp, indent = 4, sort_keys = False)\r\n",
        "\r\n",
        "  @classmethod\r\n",
        "  def load(cls, fp):\r\n",
        "    with open(fp, \"r\") as fp:\r\n",
        "      kwargs = json.load(fp = fp)\r\n",
        "    return clas(**kwargs)"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwntyBauo_QA",
        "outputId": "c411c6ab-14b4-4047-db48-bd047b32b3e9"
      },
      "source": [
        "# Encode \r\n",
        "\r\n",
        "label_encoder = LabelEncoder()\r\n",
        "label_encoder.fit(y_train)\r\n",
        "NUM_CLASSES = len(label_encoder)\r\n",
        "label_encoder.class_to_index"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Business': 0, 'Sci/Tech': 1, 'Sports': 2, 'World': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHY1TClrpXP6",
        "outputId": "b2aa32f3-2ff3-4aa8-da0e-5a234d3452db"
      },
      "source": [
        "# Converting labels to tokens \r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")\r\n",
        "\r\n",
        "y_train = label_encoder.encode(y_train)\r\n",
        "y_val = label_encoder.encode(y_val)\r\n",
        "y_test = label_encoder.encode(y_test)\r\n",
        "\r\n",
        "print (f\"y_train[0]: {y_train[0]}\")"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "y_train[0]: World\n",
            "y_train[0]: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFHTuNzTp3sq",
        "outputId": "400a6d43-f387-4c68-b2b6-344858afa046"
      },
      "source": [
        "# Class weights \r\n",
        "\r\n",
        "counts = np.bincount(y_train)\r\n",
        "class_weights = {i: 1.0/count for i, count in enumerate(counts)}\r\n",
        "print (f\"counts: {counts}\\nweights: {class_weights}\")"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "counts: [21000 21000 21000 21000]\n",
            "weights: {0: 4.761904761904762e-05, 1: 4.761904761904762e-05, 2: 4.761904761904762e-05, 3: 4.761904761904762e-05}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYDrlCrFrD_3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}